<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" xmlns:epub="http://www.idpf.org/2007/ops"
  xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" epub:prefix="index: http://www.index.com/">
<head>
<title>Chapter 06</title>
<meta content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1" name="viewport" />
<link rel="stylesheet" href="Styles/style.css" type="text/css"/>
<link rel="stylesheet" href="Styles/mobile.css" type="text/css"/> 
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script>
 
</head>

<body id="ch06" xml:lang="en-US">
<a id="p227"></a>
<section class="co" id="sec6.0">
  <div class="co_header" id="co_header_ch6">
    <h1><span class="ct_number">CHAPTER SIX</span></h1>
    <div class="seperator">&nbsp;</div>
    <h2><span class="ct_title">Summative Assessment</span></h2>
  </div>
  <div class="co_quote">
    <p class="quote_text">If you live among wolves you have to howl like a wolf.</p>
    <cite class="quote_cite">&mdash;Russian proverb</cite> </div>

<a id="p228"></a>
  <div class="co_intro">
    <div class="co_text">
    <p class="txt">If you did not howl like a wolf if you lived among them&mdash;say, you clucked like a chicken instead&mdash;you might invite unwanted attention. On the other hand, howling like a wolf if you plan to live among chickens might win you very few friends. The point is that certain characteristics and behaviors ensure success and survival in a given environment, but they might be totally useless and even dangerous in another.</p>
    <p class="txt">In the jungle kingdom of Ochawa, survival depends on an unexpected set of behaviors (Lefran&ccedil;ois, 2018). Ochawa is a small kingdom deep in a steamy jungle. One of its borders is a river, and the other is a row of rugged mountains. Ochawa&#39;s inhabitants are trapped between river and mountain: They cannot cross the river because it&#39;s too swift and deep, and they cannot traverse the mountains because the other side is an unbroken wall of sheer cliff. </p>
    <p class="txt">These circumstances present an important survival test to all the people of Ochawa every day of their lives. During the day, they must venture into the jungle for food; but every night, they need to climb to their caves high on the mountainside before the nocturnal predators that roam the jungle awaken. That is their test. Those who pass the test survive; those who don&#39;t, tough. . .</p>
    <p class="txt">The test given to citizens of Ochawa is quite different from the tests that are common in most schools. To pass the Ochawa test, you don&#39;t have to be the first to reach safety; you don&#39;t even have to be among the first 50% to do so. Nor do you have to climb higher than the others. In fact, you will pass just as surely even if you are the very last to reach safety. And you might be far less hungry. </p>
    </div>

	 <div class="co_aside" id="co_aside_ch6" alt="Group of high school students filling out assessment forms as instructor walks around. " title="Group of high school students filling out assessment forms as instructor walks around. ">
	   <div class="co_aside_cr">
	     <div class="co_src"><em>Chris Ryan/OJO Images/Getty Images Plus</em></div>
	   </div>
    </div>
  
  </div>
 <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.1 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->


<section class="page" id="sec6.1">
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.1</span> <span class="sec_title">Summative Assessment</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Questions</span> <span class="focus_q">What is the purpose of summative assessment? What are the main differences between norm-referenced and criterion-referenced interpretations of assessment data?</span></h2>
  </div>
      <div class="section-lead">
         <p class="intro">Much like daily life in Ochawa, schools present our learners with various tests&mdash;although these are not normally a matter of life and death. Still, there is sometimes a very close parallel between assessment in Ochawa and summative assessment in schools. Recall that summative assessment is the type of assessment that normally occurs at the end of an instructional sequence and is designed mainly to provide a grade.</p>
     </div>

  <div class="section-body">
 <a id="p229"></a>     
      <h2 class="h2">What Is Summative Assessment?</h2>
	  <div class="single-column">    
	  <p class="txt">In previous chapters, we distinguished among four kinds of assessment:</p>
        <ul class="bl">
        <li class="li_text"><em>Formative assessment:</em> An integral part of instruction designed mainly to provide immediate, ongoing feedback to assist learners and teachers in improving the teaching&ndash;learning process. Occurs during instruction.</li>
        <li class="li_text"><em>Placement assessment:</em> Preinstruction assessment used for making selection and placement decisions. </li>
        <li class="li_text"><em>Diagnostic assessment:</em> Assessment that often occurs prior to instruction and is then used for placement purposes. Directed at uncovering learner strengths and weaknesses, allowing for differentiated assessment and differentiated instruction. Differentiation in education refers to assessment procedures that identify important differences among learners and that lead to placements and instructional procedures that accommodate these differences. </li>
        <li class="li_text"><em>Summative assessment:</em> Assessment that typically occurs at the end of an instructional sequence and is used to summarize student progress and achievement and to provide a grade.</li>
        </ul>
      </div>

	  <div class="text_container">
        <h4><button class="ec_expand" aria-expanded="false" aria-controls="ecbox6-1">LEARN MORE</button></h4>
       <div id="ecbox6-1">
		  <div class="single-column"> 
        <p class="txt">These types of assessment differ mainly in terms of their primary purposes&mdash;to assist (<em>formative</em>), to place (<em>placement</em>), to diagnose (<em>diagnostic</em>), or to summarize (<em>summative</em>). However, although their main purposes might differ, they are not always very distinct in practice. Not only might the same formal and informal assessment procedures be used for all four purposes, but the purposes themselves are all directed toward the same end: to provide the most effective possible educational experience for all learners. </p>        
        <p class="txt">Moreover, any single assessment, no matter its primary use, might serve all four purposes. For example, when Miss Aloysius gives her third graders a quiz before starting her first arithmetic unit in September, she might use the results to do the following.</p>
 
      
		<ul class="bl">
        <li class="li_text">Divide the class into learning groups based on their individual performance&mdash;a placement function.</li>
        <li class="li_text">Look for weaknesses and strengths in individual learners&#39; understanding of basic grouping concepts&mdash;a diagnostic function.</li>
        <li class="li_text">Guide instructional and learning activities for each group&mdash;a formative function.</li>
        <li class="li_text">Grade each learner to obtain information, some of which can be shared with parents during the meet-the-teacher evening at the start of the term.</li>
        </ul>
        </div>
        <button class="ec_collapse" type="button" name="ecbox6-1"><span>X</span> close</button>  
       </div> 
	   
	  </div> 


   <div class="inner-section">
	  <h2 class="h2">Main Purposes of Summative Assessment</h2>
	  <div class="single-column">
       <p class="txt">The main purpose of summative assessment is somewhat different from the purposes of the other three categories of assessment.</p>
	   <p class="txt">Diagnostic and placement assessment are generally preinstruction assessments designed to provide information for selecting learners and placing them in appropriate groups, classes, or programs and for selecting appropriate interventions as required; formative assessment occurs during learning and is specifically directed toward improving learning and instruction.</p>
	   <p class="key-point">Summative assessment, on the other hand, occurs after instruction and is a measure of the outcomes of instructional experiences. In other words, its purpose is summative: It provides an indication of the sum or total of the effects of schooling.</p>
	   <p class="txt">As Black (1998) explains, when the chef tastes the soup, she is involved in formative assessment: She can still add herbs, thicken the broth, simmer the ingredients, and put in new spices, new vegetables, new meats, and new starches. But when the customer tastes the soup, he is engaged in summative assessment: The time to change and improve the broth is past. Now is the time for the final grade.</p>
     <a id="p230"></a>
	   <p class="txt">As mentioned earlier, a useful way of distinguishing between summative assessment and other approaches to assessment is implicit in the observation that formative, diagnostic, and placement assessment are in a sense assessment <em>for</em> learning. In contrast, summative assessment is assessment <em>of</em> learning (see Figure 6.1).</p>

	   </div>
   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.1</span><br />
          <span class="figure_title">Some distinctions between summative and formative assessment</span> </h4>
          <p class="caption">Despite their differences in principal purposes, timing, and uses, a single assessment might serve both <em>formative</em> and <em>summative</em> functions.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-1" data-type="tipTrigger">
	        <img src="figures/Figure_6.1.jpg" alt="Some of the differences between formative assessment and summative assessment are that formative assessment is assessment for learning, occurs during learning, is used to improve teaching and learning, and is where the learner is involved with the teacher in interpreting and using the results of assessment. Summative assessment is the assessment of learning that occurs after learning, is used to summarize the effects of teaching and learning, and the learner is less involved." title="Some of the differences between formative assessment and summative assessment are that formative assessment is assessment for learning, occurs during learning, is used to improve teaching and learning, and is where the learner is involved with the teacher in interpreting and using the results of assessment. Summative assessment is the assessment of learning that occurs after learning, is used to summarize the effects of teaching and learning, and the learner is less involved." id="fig_6.1"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-1">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.1.jpg" alt="Some of the differences between formative assessment and summative assessment are that formative assessment is assessment for learning, occurs during learning, is used to improve teaching and learning, and is where the learner is involved with the teacher in interpreting and using the results of assessment. Summative assessment is the assessment of learning that occurs after learning, is used to summarize the effects of teaching and learning, and the learner is less involved." title="Some of the differences between formative assessment and summative assessment are that formative assessment is assessment for learning, occurs during learning, is used to improve teaching and learning, and is where the learner is involved with the teacher in interpreting and using the results of assessment. Summative assessment is the assessment of learning that occurs after learning, is used to summarize the effects of teaching and learning, and the learner is less involved." id="fig_6.1"/>
 	  </div>
   </section>

	  <div class="single-column">
	   <p class="txt">In summary, the main purpose of summative assessment is to provide a mark or a grade that reflects progress and achievement. At the same time, however, summative assessments can be used to draw conclusions about the effectiveness of school programs and of instructional strategies. Summative assessments also say something about the appropriateness of curriculum offerings, the readiness of learners, and perhaps the characteristics of learners and teachers.</p>     
  </div>
</div>

      <h2 class="h2">Comparisons in Summative Assessment</h2>
      <div class="single-column">         
       <p class="key-point">Summative assessment almost invariably involves comparisons. The most common approach in many schools is to compare the performance of each learner to the performance of other learners.</p>

<a id="p231"></a>
	   <p class="txt">What this would mean in Ochawa is that even if all inhabitants succeeded in climbing beyond the reach of the predators, those who came in last might be sacrificed; they would have failed this <strong>norm-referenced</strong> comparison. And those who climbed first and highest might receive high praise to make up for their greater hunger.</p>
	   <p class="key-point">In some assessment situations, however, the performance of each learner is not compared to that of other students but instead is compared to a standard (a criterion).</p>
	   <p class="txt">Assume, for example, that students are expected to reach a certain level of competence&mdash;that is, to learn certain identifiable concepts and develop a repertoire of specific skills. In this case, summative evaluation might involve comparing their performance to criteria that denote attainment of these concepts and skills. Learning these concepts and skills can be viewed as defining the criteria of success&mdash;criteria we can denote as X. In a sense, X is analogous to escaping from the beasts in Ochawa: Providing they escape the beasts, those who arrive last succeed just as surely as those who climb first. This is referred to as a <em>criterion- or standards-</em><em>referenced</em> comparison.</p>
	   <p class="txt">A third option is also available: it compares each learner&#39;s performance not to a standard (as in criterion-referenced interpretations), nor to the average performance of other comparable learners (as in norm-referenced comparisons).</p>
	   <p class="key-point">Instead, learners are compared to themselves in what is termed a <span class="txt_bold">self-referenced approach to assessment</span>. </p>
	   <p class="txt">Self-referenced interpretations compare the learner&#39;s current performance with earlier performances or with performance that is expected based on ability, experience, and other personal factors. Teacher comments such as &quot;Elvira is not working up to her ability&quot; or &quot;With his long legs, Renaldo should be able to complete three more laps after 8 weeks of training&quot; are examples of self-referenced assessment.</p>
	   <p class="txt">To summarize, summative assessments typically involve one or more of three principal kinds of comparisons: </p>	
	   
	   <ol class="nl">
	      <li class="li_text"><em>Norm-referenced interpretations:</em> Comparisons with the performance of other similar learners. </li>
	      <li class="li_text"><em>Criterion- or standards-based interpretations:</em> Comparisons with a predefined criterion or standard of acceptable or expected performance.</li>
	      <li class="li_text"><em>Self-referenced approach to assessment:</em> Comparisons of each learner with him- or herself, often reflecting expectations based on measured or assumed ability, background, and personal factors such as motivation and parental encouragement (see Table 6.1).</li>
	   </ol>
     </div>

 <a id="p232"></a>
 <div class="tbl_scroll_on_mobile">
<table class="tbl-xl">
          <caption class="tbl_name">
          <span class="tbl_number">Table 6.1</span> <br />
          <span class="tbl_title">Comparison bases for summative assessment</span>
          </caption>
          <thead class="tbl_header">
            <tr>
              <th>Comparison group</th>
              <th>Type of comparison</th>
              <th>Explanation</th>
              <th>Example</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Other learners</td>
              <td>Norm-referenced</td>
              <td>Learner&#39;s performance is compared with that of peers.</td>
              <td>The average score of the group, no matter what it is, is assigned a C grade, and all other scores are distributed around this mark.</td>
              
            </tr>
            <tr >
              <td>Predetermined standards</td>
              <td>Criterion-referenced</td>
              <td>Learner is judged relative to some standard of acceptable performance.</td>
              <td>Learners are assigned a &quot;pass&ndash;fail&quot; grade according to whether they achieve at a predetermined level.</td>          
            </tr>
            <tr>
              <td>Self</td>
              <td>Self-referenced</td>
              <td>Learner&#39;s performance is assessed relative to previous or expected performance.</td>
              <td>Learners are evaluated in terms of their improvement.</td>   
            </tr>
          </tbody>
     </table>
     </div>

   <div class="single-column"> 
       <p class="txt">Each of these three approaches to interpreting test scores&mdash;criterion-referenced, norm-referenced, and self-referenced&mdash;can be used for summative purposes.</p>
   </div>

</div>
<script type="text/javascript" src="Scripts/app-min.js"></script>
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.2 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->

<section class="page" id="sec6.2">
  <div class="section-header">

    <h1 class="h1"><span class="sec_number">6.2</span> <span class="sec_title">Norm-Referenced Comparisons</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Questions</span> <span class="focus_q">How are norm-referenced comparisons used? What are the advantages and disadvantages of norm-referenced comparisons?</span></h2>
  </div>
   <div class="section-lead">
       <p class="intro">Norm-referenced comparison is the dominant form of assessment in most schools. It involves comparing an individual student&#39;s performance to that of others. In a sense the performance of other students sets the norm or the standard&mdash;as opposed to having a standard (criterion) set by state or local authorities.</p>     
  </div>

<div class="section-body">
   <div class="single-column">        
          <p class="key-point">Norm-referenced interpretations lend themselves well to competitive approaches to teaching but are poorly suited to more cooperative approaches. </p>
          <p class="txt">Competitive approaches, explain Johnson and Johnson (1999), are characterized by classrooms where learners engage in a win&ndash;lose struggle to see who is the best, the fastest, and the smartest. Competition makes sense when success and failure depend on how well each learner does relative to other learners. In contrast, cooperative approaches are marked by groups who work together and help each other to make sure that everybody succeeds. Cooperation makes sense when success is judged not in terms of performance relative to other students but in terms of performance in relation to clear criteria. </p>
   </div>
  
	<a id="p233"></a>
	 <figure class="photo-right"><img src="Images/6.1.jpg" alt="Middle school students in a classroom taking a test. A girl is leaning over to try to see the paper of the student in front of her." title="Middle school students in a classroom taking a test. A girl is leaning over to try to see the paper of the student in front her." id="img6.1"/>
        <figcaption>
          <p class="cr">RubberBall/SuperStock</p>
          <p class="caption">The most common norm-referenced tests are objective, multiple-choice tests such as the one these students are taking. Such tests provide an easy basis for comparing these learners to each other. If the test is a standardized test, they can also be compared to students in other schools, in the entire state, or in the nation. But the validity and fairness of comparisons might be suspect if cheating occurs. </p>
        </figcaption>
      </figure>
	
        <div class="single-column">
         <p class="txt">Norm-referenced interpretations often rely on assessments based on <strong>objective tests</strong>. These are tests that consist of items that require short, factual, unambiguous answers. Objective tests can usually be scored by anyone who either has an answer key or who happens to know the correct answers. There tends to be high agreement among scores from different markers.</p>

          <p class="txt">The most common objective tests are multiple-choice tests. Many of these are commercially developed. Often they are based on national norms rather than on local curricula. They are usually designed to rank students relative to the performance of a representative sample of similar students&mdash;referred to as a <strong>norming group</strong>. The emphasis of such tests is less on covering curriculum content that might have been mastered than on selecting items that most clearly differentiate among examinees. As a result, standardized tests do not usually ask questions that everyone might answer correctly. Instead, they ask questions that only a percentage of test takers can answer. (Teacher-made objective tests are discussed in Chapter 8; standardized tests are the subject of Chapter 10.)</p>
        </div>


      <div class="inner-section">
        <h2 class="h2">Uses of Norm-Referenced Comparisons</h2>
          <div class="single-column">
     
           <p class="txt">Much of the assessment that occurs in the classroom is not based on commercially developed, standardized tests but on teacher-made assessments, many of which are used for norm-referenced interpretations. Based on these assessments, students in a class may be ranked according to how well they perform relative to each other. </p>

          <p class="key-point">Ranking is one way of comparing an individual&#39;s performance to that of others exposed to the same assessment. </p>

          <p class="txt">If Benjamin is ranked first following a third-grade arithmetic quiz, this simply means that he has performed better than all his third-grade classmates. The norm that his performance is being compared to has been established by the performance of his entire class.</p>

          <p class="txt">Ranking is sometimes expressed as the percentage of students below a given point. For example, Benjamin&#39;s performance is at the 99th <strong>percentile</strong>, meaning that 99% of his classmates score at or below his score. A percentile is simply the point at or below which a given percentage of cases fall (percentiles and other important statistics are discussed in Chapter 9). </p>

          <p class="key-point">Another approach to reporting norm-referenced grades is to compare each test taker&#39;s score to the average of the entire group. </p>

	<a id="p234"></a>
          <p class="txt">Say, for example, that the average of all scores obtained by Benjamin&#39;s class on this arithmetic test was 15 out of 40. Benjamin&#39;s performance is clearly better than average: He ranked first. So, if the teacher is using a letter grading system&mdash;say A, B, C, D, and F&mdash;Benjamin would probably be given an A.</p>

          <p class="txt">Nevertheless, for a variety of reasons that we will look at in Chapter 9, Benjamin&#39;s A, all by itself, might be highly misleading. If his classmates did extraordinarily poorly, he might have answered only 19 of the 40 test items correctly and done better than anyone else. Conversely, if they did exceptionally well, he might have had to answer 39 items correctly to be at the 99th percentile. If he answered only 19 correctly, he would have done rather poorly relative to the rest of the class.</p>
		  </div>
     </div>

  <h2 class="h2">Evaluation of Norm-Referenced Comparisons</h2>
  <div class="single-column">
            <p class="txt">The previous example highlights a significant disadvantage of norm-referenced grading when norms are based on the performance of a small group such as a single class. </p>

          <p class="key-point">As Figure 6.2 shows, the group you belong to can make an enormous difference under these circumstances.</p>
  </div>

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.2</span><br />
          <span class="figure_title">Interpreting norm-referenced scores on teacher-made tests</span> </h4>
          <p class="caption">Hypothetical distributions of identical norm-referenced tests given to two classes. If Sally were in class A, her rank would be at a respectable 64th percentile. But if she were in class B, the same score would place her just above the 40th percentile.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-2" data-type="tipTrigger">
	        <img src="figures/Figure_6.2.jpg" alt="Graph with two curves showing the different distributions of test scores in two different classes, where class B has higher scores than class A. In class A, Sally&#39;s scores would be at the 64th percentile, but in class B, where marks are much higher, her mark would be at the 40th percentile." title="Graph with two curves showing the different distributions of test scores in two different classes, where class B has higher scores than class A. In class A, Sally&#39;s scores would be at the 64th percentile, but in class B, where marks are much higher, her mark would be at the 40th percentile." id="fig_6.2" />
	     </a>
   </figure>

   <section class="tipBox" id="fig6-2">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.2.jpg" alt="Graph with two curves showing the different distributions of test scores in two different classes, where class B has higher scores than class A. In class A, Sally&#39;s scores would be at the 64th percentile, but in class B, where marks are much higher, her mark would be at the 40th percentile." title="Graph with two curves showing the different distributions of test scores in two different classes, where class B has higher scores than class A. In class A, Sally&#39;s scores would be at the 64th percentile, but in class B, where marks are much higher, her mark would be at the 40th percentile." id="fig_6.2"/>
 	  </div>
   </section>


	<a id="p235"></a>

        <div class="single-column">
          <p class="key-point">Of course, when norms are based on the performance of large, comparable samples, which is the case for standardized tests, these disadvantages disappear. </p>

          <p class="txt">Now all examinees are being compared to the same highly representative norms. Performing at the 99th percentile&mdash;or at the 10th, meaning that approximately 90% of the norming group did better&mdash;has consistent meaning no matter how the rest of Benjamin&#39;s class might have done.</p>

          <p class="txt">For several reasons, norm-referenced interpretations are widely used in schools.</p>
           <ul class="bl">
                <li class="li_text">They provide an effective means of comparing students. If, for example, there are limited resources for programs for gifted and talented learners, a valuable and fair way of selecting candidates for admission to these programs is to rank them. Ranks and percentiles are especially meaningful if they compare learners to state- or nationwide norms rather than only to their classmates.</li>
                <li class="li_text">Norm-referenced comparisons based on standardized tests provide quick, inexpensive, and useful information about the extent to which students have learned what they were expected to learn.</li>
                <li class="li_text">Norm-referenced interpretations are often more easily developed by teachers than are criterion-based comparisons.</li>
                <li class="li_text">Norm-referenced tests provide valuable information for predicting performance in later grades (Thorsen, 2014).</li>      
           </ul>
		   <p class="key-point">It is important to recognize that although a score such as a rank or a percentile indicates how well or how poorly Benjamin has performed relative to his classmates, it says nothing about any specific competencies he might have acquired&mdash;or failed to acquire. </p>

          <p class="txt">True, we can assume with some confidence that if Benjamin is at the 99th percentile on a nationally standardized achievement test, he will have acquired most of the relevant knowledge and skills for his grade level. However, his score being at the 99th percentile relative to his small class tells us much less about what he has learned, especially if that class happens to be disadvantaged&mdash;or advantaged&mdash;in one or more ways.</p>
       </div>
</div>
  <script type="text/javascript" src="Scripts/app-min.js"></script>


</section>



<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.3 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->


<section class="page" id="sec6.3">

  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.3</span> <span class="sec_title">Criterion-Referenced Comparisons</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">How can standards be used for criterion-referenced comparisons?</span></h2>
  </div>

  <div class="section-lead">
  <p class="intro">In norm-referenced summative assessment comparisons, the performance of the class, or of the school, sets the norm (the criterion). Note, however, that this type of norm is quite different from the predetermined standards that characterize <strong>criterion-referenced</strong> assessment. </p>  
  </div>

<div class="section-body">
   <div class="single-column">
         <p class="key-point">Whereas norm-referenced interpretations compare a test score to scores obtained by other test takers, criterion-referenced interpretations compare a test taker&#39;s score to a predetermined standard, which usually takes the form of criteria that are expressions of desired, expected, or required performance. </p>

	<a id="p236"></a>
          <p class="txt">The standards (the criteria) for both criterion-referenced and norm-referenced comparisons might have very similar sources. For example, both might be based on state-prescribed performance requirements at a specific grade level, whereby the standards have been determined by looking at the performance of a large, representative group on relevant assessments. The distinction is that criterion-referenced assessment evaluates the learner in terms of a predetermined standard; norm-referenced assessment evaluates the learner in relation to other learners. In the Ochawa jungle example, assessment is criterion referenced. The criterion is obvious: Did you climb high enough and early enough? The grade is equally clear: life or death.</p>

          <p class="txt">Say, for example, that the criterion for success in Ms. Espinaco&#39;s third-grade arithmetic class is that learners understand parentheses and that, as a result, they be able to solve four problems of the kind shown in Figure 6.3. Furthermore, they must be able to do so within 5 minutes and with no more than one error. Doing so successfully is the criterion for success in this arithmetic unit; it is the <em>standard</em> students are expected to reach after relevant instruction. </p>

          <p class="txt">Assessment that determines whether each third grader in Ms. Espinaco&#39;s class has reached this level of competence would be an example of a criterion-referenced approach (also called <em>standards-based</em> assessment). It is important to note that a criterion-referenced approach does not involve the use of a different kind of test; rather, it simply involves a different sort of interpretation of test scores based on a different comparison&mdash;in this case, a comparison to a standard (rather than a comparison to other learners (norm-referenced) or to the individual learner (self-referenced). Hence it is more accurate to refer to criterion-referenced interpretations or comparisons rather than to criterion-referenced tests or assessments. </p> 
     </div>


   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.3</span><br />
          <span class="figure_title">Example of a brief criterion-referenced test in third-grade arithmetic</span> </h4>
          <p class="caption">A criterion-referenced test is typically interpreted as a pass&ndash;fail test. In this case third graders are deemed to have passed (to have reached the passing <em>criterion</em>) when they correctly solve four of the five problems. Criteria for criterion-referenced tests are often based on state-mandated standards. The same test could also be used for norm-referenced assessment but would involve comparing each learner&#39;s response to the performance of the entire group of learners. Whether a test is criterion-, norm-, or self-referenced is not inherent in the test but is defined by how the test is interpreted and used.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-3" data-type="tipTrigger">
	        <img src="figures/Figure_6.3.jpg" alt="Third-grade test contains a set of 5 equations." title="Third-grade test contains a set of 5 equations." id="fig_6.3"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-3">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.3.jpg" alt="Third-grade test contains a set of 5 equations." title="Third-grade test contains a set of 5 equations." id="fig_6.3"/>
 	  </div>
   </section>


	<a id="p237"></a>
	 <div class="inner-section">
	  <h2 class="h2">Standards in Education</h2>
	  <div class="single-column">
               <p class="txt">As we saw in Chapter 1, <em>standards</em> is a term that is used interchangeably with the term <em>goals</em>. Like the term <em>goal</em>, <em>standard</em> might mean an intended outcome. But, like the term <em>criterion</em>, it might also mean a required or expected level of knowledge or performance by which something can be judged. Hence, the terms <em>criterion</em> and <em>standard</em> are often used interchangeably, as they are here.</p>
	

  

	
        <p class="txt">Criterion-based interpretations of assessment depend on having clear, measurable criteria. These might be derived from lists of standards or broad goals that can serve as guides for teachers and school systems as they develop learning targets. Bloom&#39;s taxonomy of educational objectives and revisions thereof, described in Chapter 4, provide one approach. Recall that one part of the taxonomy describes a series of activities that underlie our cognitive processing&mdash;activities like remembering, understanding, analyzing, evaluating, and creating. Figure 4.4, for example, lists a large number of verbs for each of these activities&mdash;verbs such as <em>indicate</em>, <em>demonstrate</em>, <em>draw</em>, <em>calculate</em>, <em>appraise</em>, <em>produce</em>, and so on. Each of these verbs suggests different instructional and assessment procedures.</p>
 </div>
	<div class="text_container">
          <h4><button class="ec_expand" aria-expanded="false" aria-controls="ecbox6-2">LEARN MORE</button></h4>
      <div id="ecbox6-2">
		 <div class="single-column">
        <p class="txt">ESSA requires every state to create educational standards to guide educators and test developers. The CCSS, developed by the National Governors Association and the Council of Chief State School Officers (CCSSO), are intended to provide clear and consistent learning goals consistent with helping prepare students for college, career, and life. The standards clearly indicate what students are expected to learn at each grade level so that every parent and teacher can understand and support their learning (CCSSO, 2018). The CCSS, which have been adopted by most states, describe the skills and knowledge that define minimum competency in core subjects at each grade level. All schools are encouraged to adopt and apply these standards. </p>
       <p class="txt">The development of state standards in education underlies what is termed <em>standards-based education</em>. The term describes educational systems in which instructional and assessment methods are directed toward reaching explicit academic and performance levels. Standards-based education, and the related practice of standards-based grading, are very much part of ongoing educational reforms. Standards-based grading is an approach to grading that looks specifically at the learner&#39;s performance with respect to clearly defined statewide standards denoting proficiency or mastery.</p>
       
		  
		        <figure class="photo-right-small"><img src="Images/6.2.jpg" alt="Student standing at the chalkboard, looking at her notes while holding a piece of chalk up to the board. On the board is a geometry problem." title="Student standing at the chalkboard, looking at her notes while holding a piece of chalk up to the board. On the board is a geometry problem." id="img6.2"/>
        <figcaption>
          <p class="cr">Pkline/iStock/Getty Images Plus</p>
          <p class="caption">Common core standards are statements of basic levels of performance and achievement that are expected in core subjects at each grade level and are common to more than one school. For example, high school students should be able to apply trigonometry to general triangles. </p>
        </figcaption>
      </figure> 
			 </div> 
			 
        <button class="ec_collapse" type="button" name="ecbox6-2"><span>X</span> close</button>      
      </div> 
	 </div> 

    </div>
  
  <a id="p238"></a>
<h2 class="h2">Aligning Assessments With Standards</h2>
  <div class="single-column">
          <p class="txt">An ongoing issue in education has to do with what is termed <em>educational alignment</em>&mdash;the need to align local curriculum with state-mandated standards and to adjust instruction and assessment accordingly. </p>
          <p class="key-point">The degree of alignment between assessment procedures and content standards serves as an indication of the validity of the assessments. In addition, research makes it clear that alignment among standards, instruction, and assessment is associated with a higher likelihood of reaching those standards (Traynor, 2017). </p>
          <p class="txt">For example, when Troia and associates (2018) compared alignment between state writing standards and student writing achievement, they found that students from states characterized by the closest alignment between their standards and national assessments had significantly higher scores.</p>
          <p class="txt">Alignment between assessments and educational standards is usually achieved in one of several ways.</p>
		  <ol class="nl">
		  	<li class="li_text">Standards are developed first and are then used as blueprints for developing assessments. As we saw in Chapter 1, this illustrates the <em>backward design</em> approach to curriculum and assessment.</li>
		  	<li class="li_text">Experts are called in to review the alignment between assessments and content after both have been developed. However, experts do not always agree on the extent to which there is alignment. For example, Traynor and Merzdorf (2018) found high disagreement among educators who were recruited to judge the extent to which test items were aligned with specific curriculum standards.</li>
		  	<li class="li_text">Content standards and assessments are analyzed, and alignment models are used to quantify the match between them.</li>
	     </ol>
		  <p class="txt">The last of these approaches, the application of models following analysis of assessments and content, is widely used by state educational authorities in an effort to ensure that the standardized statewide achievement tests they use reflect core standards (see Chapter 10). One commonly used model is similar to what might be based on a taxonomy such as Bloom&#39;s. It looks at alignment with respect to the content of both standards and assessments, and it looks at the cognitive activities required by each. Degree of alignment is reflected in how closely the content and cognitive activity requirements parallel each other on both assessments and standards. Thus, if an educational standard stresses being able to apply knowledge in new situations, a well-aligned assessment procedure would require that the learner demonstrate applications.</p>

    <a id="p239"></a>
          <p class="txt">Experts often don&#39;t agree, as Traynor and Merzdorf (2018) report following their analysis of more than 1,000 state reviews of alignment between standards and assessments. This strongly suggests that alignment is not as simple as it might seem. Not only are standards sometimes unclear, but whether a high or low score on an assessment actually reflects attainment of the standard is not always certain. Traynor and Merzdorf suggest that expert agreement might be increased if experts were selected from among individuals who have had a significant amount of experience teaching in elementary and secondary schools. Experienced teachers are more likely to understand the paths a student takes to a solution&mdash;that is, the cognitive skills involved in responding to an item.</p>
      

<div class="video-center">
	<p class="video-head">Summative Assessment</p>
	
	<p class="video-caption">A school superintendent talks about the role of summative assessment.</p>

<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1501441/sp/150144100/embedIframeJs/uiconf_id/24035961/partner_id/1501441?iframeembed=true&amp;playerId=kaltura_player&amp;entry_id=0_8h89evkd&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;flashvars[Kaltura.addCrossoriginToIframe]=true&amp;&amp;wid=0_0uzradze" width="400" height="285" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0" title="Kaltura Player"></iframe>

	<div class="clear-both"></div>
	
<p class="media">
Media not working on mobile? Try opening this eBook on your desktop or laptop computer.</p>
<div class="clear-both"></div>

<p class="video-caption">Critical-Thinking Questions</p>
<ul class="bl">
<li class="li_text">What should a teacher do if a majority of their students demonstrate a lack of learning in a summative assessment? What might cause this to occur? </li>
<li class="li_text">Why might a student show proficiency in formative assessments and then fail a summative assessment?</li>    

	</ul>
<div class="clear-both"></div>				
</div>       
      
  </div>

 <div class="inner-section">
	  <h2 class="h2">Bases for Criterion-Referenced Comparisons</h2>
	  <div class="single-column">
          <p class="txt">Using <strong>common core standards</strong> as a basis for establishing proficiency and competency criteria for learners gives teachers a basis for criterion-referenced comparisons. Because criteria are generally expressed as specific competencies (for example, skills, understanding, and performance levels), criterion-referenced approaches to assessment and grading provide the teacher with very specific information about what the individual has learned. Also, specifying criteria from the outset may do much to clarify the teacher&#39;s role. Few instructional guides are more useful than those that provide a clear view of learning objectives defined in terms of specific performance criteria.</p>
          <p class="txt">Both norm-referenced and criterion-referenced comparisons can be based on teacher-made tests or on commercially prepared standardized tests. An example of a criterion-referenced approach based on a standardized test is the written test most of us had to take to obtain a driver&#39;s license. In most such tests, the criterion is a specific score. In California, for example, if you are over 18, the test for a regular driver&#39;s class C license consists of 36 multiple-choice questions. The criterion for passing is 31 correct responses. If you are under 18, the test consists of 46 items, 38 of which you must answer correctly. Accordingly, unlike the case for a norm-referenced assessment, the relative performances of all those who take the test in a given month is irrelevant to whether a test taker passes or fails. It makes no difference how well&mdash;or how poorly&mdash;others perform: As long as learners meet the criterion, they will pass. (And if they fail, they can take the test again, although it might be a different test because there are five different forms of it.)</p>
          <p class="txt">By definition, criterion-referenced approaches depend on a clear understanding of instructional objectives and on knowing what an acceptable level of proficiency and performance is. The test maker needs to answer questions like these: How many items must drivers answer correctly to demonstrate that they are qualified to operate a motor vehicle? How rapidly and accurately must the student be able to translate the Spanish poem to demonstrate proficiency at a fourth-grade level?</p>
          <p class="key-point">To devise criterion-referenced assessments, teachers need to be able to describe instructional objectives in terms of measurable competencies and achievements. </p>
          <p class="txt">These descriptions are the criteria that the teacher will then use in criterion-referenced grading. Without a clear statement of learning criteria, it would not be possible to devise assessments to determine whether instructional objectives have been reached. Accordingly, criterion-referenced approaches to assessment have the following characteristics.</p>

    <a id="p240"></a>
		  	<ul class="bl">
 		  	       <li class="li_text">They are typically based on tests that include items that are directly relevant to instructional objectives rather than items that are useful for discriminating among students. For example, whereas norm-referenced approaches are often based on tests that include a range of easy to more difficult items and so tend to produce a wide range of scores, a criterion-referenced approach might be based on a test that produces only two grades (pass or fail; satisfactory or unsatisfactory).</li>
 		  	       <li class="li_text">They allow instructors and parents to determine and describe relatively precisely the learner&#39;s achievement and progress. For example, they might permit the teacher to describe the specific learning tasks that have been mastered or to establish whether a predetermined standard of acceptable performance has been reached.</li>
		  	       <li class="li_text">In many instances they are based on the sorts of assessments on which all learners will succeed. In contrast with norm-referenced interpretations, discriminating among learners is not an objective; ascertaining that all&mdash;or most&mdash;learners have reached predetermined criteria is their defining purpose. As explained later in this chapter in the discussion of Bloom&#39;s <em>mastery learning</em>, criterion-referenced interpretations are especially well suited to competency-oriented classrooms.</li>
           </ul>

      </div>
    </div>
</div>
<script type="text/javascript" src="Scripts/app-min.js"></script>
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.4 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->


<section class="page" id="sec6.4">
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.4</span> <span class="sec_title">Self-Referenced Comparisons</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What are some of the advantages and disadvantages of self-referenced comparisons?</span></h2>
  </div>
  <div class="section-lead">
       <p class="intro">Criterion-referenced interpretations compare the learner&#39;s performance to some predetermined standard; norm-referenced approaches compare the learner&#39;s performance to that of a group of peers. A third option, a <em>self-referenced approach to assessment</em>, compares the learner&#39;s current performance to the same individual&#39;s performance at some earlier time, or it compares the learner&#39;s performance with performance expected on the basis of ability and perhaps other factors such as experience.  </p>

   </div>


<div class="section-body">
     <div class="single-column">
          <p class="txt">Teacher comments such as &quot;Ellie is doing better than expected&quot; or &quot;Gabe can do a lot better&quot; are examples of self-referenced comparisons. These comments reflect the teacher&#39;s expectations of possible and probable achievement based on the individual&#39;s characteristics. These characteristics might include information about the student&#39;s ability, previous achievement, prior related learning, and a variety of personality factors such as determination, motivation, and persistence. </p>
          <p class="txt">An ability-based, self-referenced approach to assessment usually means that students who achieve according to their ability or who do even better than what might be expected receive high grades. The term <strong>overachievement</strong> is sometimes used to describe these learners. In reality, the word is an oxymoron: Overachieving is about as likely as an athlete&#39;s being able to give 130%. In addition, the word <em>overachiever</em> sometimes has negative connotations&mdash;like Shana sarcastically saying, &quot;Oh, he&#39;s real smart,&quot; which might imply, &quot;His high grades are making everybody else look bad.&quot; Or the teacher, Ms. O&#39;Connor, saying, &quot;I didn&#39;t expect him to do this well,&quot; which can be interpreted as meaning, &quot;He must be overachieving because I don&#39;t think he&#39;s that smart.&quot;</p>

	 <a id="p241"></a>
			<p class="txt">In contrast to learners who achieve at unexpectedly high levels, some learners for whom there are high expectations based on ability do not perform up to expectations: They would receive lower grades using self-referenced comparisons. These learners are sometimes described as <strong>underachievers</strong>. </p>
    </div>   
  
    <div class="inner-section">
      <h2 class="h2">Problems With Self-Referenced Comparisons</h2>
      <div class="single-column">
          <p class="key-point">One problem associated with self-referenced comparisons based on ability is that teachers are not always very good judges of learners&#39; abilities. Nor can they easily identify and differentiate among all the various abilities and characteristics that contribute to school achievement. </p>
          <p class="txt">For example, research conducted by Irizarry and Cohen (2018) illustrate how students&#39; racial and cultural background can serve to bias teacher perceptions. In this study, Asian learners received disproportionally higher teacher ratings in mathematics. In contrast, African Americans had lower language and literacy ratings. </p>
          <p class="txt">Similarly, there is considerable research indicating that teachers&#39; perceptions of their students&#39; abilities can be affected by the students&#39; personal characteristics. Hansen (2016) looked at teachers&#39; perceptions of pupils&#39; ability and the teachers&#39; ratings of the pupils&#39; attractiveness. The study focused on some 9,233 children who had been judged by their teacher as either attractive (81% of the entire sample) or unattractive (19% of the sample). The &quot;unattractive&quot; category included children described as &quot;undernourished,&quot; &quot;slovenly,&quot; or &quot;dirty.&quot; Teachers had also been questioned about their perceptions of these children&#39;s abilities and behavior. Results showed that pupils judged to be attractive were significantly more likely to receive higher teacher ratings in all areas examined: general knowledge, numerical skills, reading, and oral skills. In fact, twice as many of the attractive students were rated as having outstanding ability than were unattractive students (26.7% of all pupils judged &quot;attractive&quot; compared with only 13.3% of those judged &quot;unattractive&quot;). And as Figure 6.4 shows, comparisons of teacher ratings with more objective measures indicate that the &quot;attractive&quot; children are significantly more likely to be overrated by their teachers, and the &quot;unattractive&quot; are more likely to be underrated.</p>
     </div>

	 <a id="p242"></a>

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.4</span><br />
          <span class="figure_title">Teacher ratings of students based on perceived attractiveness</span> </h4>
          <p class="caption">Teachers are more likely to rate attractive students as high in ability. Their ratings are more likely to be overratings for attractive students and more likely to be underratings for unattractive students.</p>
		  <p class="src">Based on &quot;The Relationship Between Teacher Perceptions of Pupil Attractiveness and Academic Ability,&quot; by K. Hansen, 2016, <span class="no_italic">British Educational Research Journal, 42,</span> pp. 376&ndash;398. doi:10.1002/berj.3227</p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-4" data-type="tipTrigger">
	        <img src="figures/Figure_6.4.jpg" alt="Bar graph showing that teachers are approximately twice as likely to rate attractive rather than unattractive students as having outstanding ability (26.7% of those judged attractive but only 13.3% of those judged unattractive). They are also more likely to underrate the ability of less attractive students (80% were underrated as opposed to 77.2%) and more likely to overate the ability of those judged attractive (47.1% compared with 39%)." title="Bar graph showing that teachers are approximately twice as likely to rate attractive rather than unattractive students as having outstanding ability (26.7% of those judged attractive but only 13.3% of those judged unattractive). They are also more likely to underrate the ability of less attractive students (80% were underrated as opposed to 77.2%) and more likely to overate the ability of those judged attractive (47.1% compared with 39%)." id="fig_6.4"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-4">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.4.jpg" alt="Bar graph showing that teachers are approximately twice as likely to rate attractive rather than unattractive students as having outstanding ability (26.7% of those judged attractive but only 13.3% of those judged unattractive). They are also more likely to underrate the ability of less attractive students (80% were underrated as opposed to 77.2%) and more likely to overate the ability of those judged attractive (47.1% compared with 39%)." title="Bar graph showing that teachers are approximately twice as likely to rate attractive rather than unattractive students as having outstanding ability (26.7% of those judged attractive but only 13.3% of those judged unattractive). They are also more likely to underrate the ability of less attractive students (80% were underrated as opposed to 77.2%) and more likely to overate the ability of those judged attractive (47.1% compared with 39%)." id="fig_6.4"/>
 	  </div>
   </section>


  


      <div class="single-column">
          <p class="key-point">A second problem related to self-referenced approaches to assessment is that evaluations based on either ability or progress are typically vague and confusing both for parents and for learners. </p>
          <p class="txt">For example, when a student of lower ability nevertheless performs at a high level and receives the same grade as a student with higher ability who is underachieving, does this mean that the two students have achieved at the same level? And the comment that &quot;Dante is improving&quot; says nothing specific about Dante&#39;s performance relative to instructional objectives or relative to other students.</p>
          <p class="key-point">A third problem with assessing students on the basis of expected performance is that teacher expectations are often strongly affected by a variety of factors that are not always related to ability. </p>
          <p class="txt">As de Boer, Timmermans, and Van der Werf (2016) point out, expectations are often tied to socioeconomic and language factors. They may also be profoundly influenced by race, class, and gender (Riley &amp; Ungerleider, 2012). And although these factors may sometimes be related to achievement, they are less likely to be related to innate ability. </p>
          <p class="txt">An associated problem with assessment based on expected achievement is that a growing body of evidence suggests that teacher expectations themselves affect learner outcomes (e.g., de Boer et al., 2016; Pantaleo, 2016). This may be partly because teachers&#39; expectations influence the sorts of learning opportunities they provide their learners. Unfortunately, however, expectations for some students are inappropriate&mdash;as we saw in the Hansen (2016) study, in which teachers tended to overestimate the ability of the more attractive students. As a result, the learning opportunities provided for these students may be inadequate and unfair. In contrast, the overly optimistic expectations teachers have for some learners may place too great a burden on them and might even result in judgments of underachievement.</p>
	 </div> 
	 </div>

	 <a id="p243"></a>
<h2 class="h2">Uses of Self-Referenced Comparisons</h2>
<div class="single-column">
          <p class="txt">In light of these problems and weaknesses, self-referenced approaches are not generally recommended as a basis for grading, especially in the higher grades. However, as we will see in Chapter 11, evaluative comments relating to progress and even to expected achievement are highly common on report cards, especially in early grades. </p>
          <p class="txt">Even though self-referenced comparisons are often vague and confusing and are uncommon as a grading system, they can be very useful for a variety of purposes in the classroom. </p>
          <p class="key-point">First, a self-referenced approach can be highly beneficial for teachers to encourage learners to set goals that are challenging but within with their capabilities. </p>
          <p class="txt">They can then be encouraged to monitor and control their learning activities with a view to helping them become self-regulated learners&mdash;learners who have learned how to learn. These are learners who have developed strong self-assessment skills and are therefore able to set their own learning goals as well as evaluate and direct their activities to maximize the attainment of these goals. Self-regulated learning is autonomous, self-directed learning. Becoming a self-regulated learner is highly dependent on accurate monitoring of learning progress&mdash;that is, on self-referenced evaluations (Chatzisarantis et al., 2016). </p>
          <p class="key-point">Second, self-referenced approaches to assessment can serve an important motivational function. </p>
          <p class="txt">Informing learners and parents that Jacob is doing better than expected might be highly rewarding for little Jake, and he might be encouraged to redouble his efforts. Similarly, the evaluative comments that &quot;Vanessa is capable of doing much better in arithmetic&quot; or &quot;Sammy is progressing well in language literacy&quot; might motivate Vanessa and Sammy to work even harder than they have been.</p>
          <p class="key-point">Third, self-referenced comparisons can be helpful when the teacher is interested in a student&#39;s learning progressions&mdash;in the learner&#39;s mastery of a given sequence of cognitive skills and understanding. </p>
          <p class="txt">Self-referenced interpretations, whether they are based on comparisons with expected performance or relate to student improvement, can suggest critical interventions to the teacher. And they might indicate to the learner that certain cognitive strategies are better than others for different kinds of learning.</p>
          <p class="key-point">Also, in certain endeavors, self-referenced comparisons are the most logical and informative approach. </p>

	 <a id="p244"></a>
		  <p class="txt">For example, a student athlete preparing for the annual track meet might, along with her coach, begin by recording her usual fastest times. Their ultimate target&mdash;say, winning the 100-meter dash&mdash;is based on the expected winning time based on previous years&#39; performances. Now the athlete sets sequential targets and monitors her progress toward these targets over the training period. This is a clear example of a self-referenced approach based on individual progress.</p>    

</div>


  </div>  

   <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>




<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.5 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->
 

<section class="page" id="sec6.5">


  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.5</span> <span class="sec_title">Appraisal of Norm-, Criterion-, and Self-Referenced Comparisons</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Questions</span> <span class="focus_q">How might a single test be used for all three approaches to summative assessment? When might one approach be preferred over another?</span></h2>
  </div>
  <div class="section-lead">
       <p class="intro">The primary difference between the three approaches to summative assessment&mdash;norm-referenced, criterion-referenced, and self-referenced&mdash;is that each approach compares the learner&#39;s performance to a different reference group.</p>

   </div>


<div class="section-body">
<div class="single-column">
          <p class="txt">Norm-referenced approaches compare a learner&#39;s performance to that of others in the same or a similar group, criterion-referenced approaches refer to a predetermined standard, and self-referenced approaches are based on comparisons with the self. </p>
          <p class="key-point">However, the same tests might be used for each of these comparisons. </p>
          <p class="txt">As an example of different uses of a single measuring instrument, Mr. Antoine administers a standardized mathematics achievement test to his sixth graders. Knowing that there is space for three students in the math enrichment club, he then uses the results to rank his students so that he can select the top three for admission into this club. This is an example of norm-referenced interpretation. The level of achievement required to be selected for entry into the math enrichment club depends on the performance of all members of this sixth-grade class.</p>
          <p class="txt">At the same time, however, Mr. Antoine might use the test to identify those of his students who have not yet mastered an understanding of concepts dealing with percentages, ratio, rate, and rounding. Those he deems to have met the criteria for understanding these concepts have answered at least four of test items 5, 7, 9, 12, 43, and 67 correctly. Thus, the standardized test that had been part of a norm-referenced interpretation is now used for a criterion-referenced approach.</p>
          <p class="txt">Furthermore, Mr. Antoine compares the performance of each of his students to that student&#39;s performance on the same test taken 3 months earlier. This step, which allows him to gauge individual progress during the term, illustrates the use of this standardized test for self-referenced observations. Table 6.2 summarizes these concepts, and the case study in <em>Applications: Which Interpretation of Assessment Data is Needed?</em> provides another example of how the three approaches might be used.</p>
</div>

	 <a id="p245"></a>
<div class="tbl_scroll_on_mobile">
<table class="tbl-xl">
          <caption class="tbl_name">
          <span class="tbl_number">Table 6.2</span> <br />
          <span class="tbl_title">Three assessment approaches</span>
          </caption>
          <thead class="tbl_header">
            <tr>
              <th>Norm-referenced</th>
              <th>Criterion-referenced</th>
              <th>Self-referenced</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Learner&#39;s performance is compared to that of others in same (or similar group). </td>
              <td>Learner&#39;s performance is compared to an external, predetermined standard. </td>
              <td>Learner&#39;s performance is compared to learner&#39;s own past performance. </td>
            </tr>
               <tr>
              <td>Often based on standardized tests, but also relies on teacher-made tests. </td>
              <td>Based on standardized or teacher-devised assessments. </td>
              <td>Based on a variety of informal and formal assessment procedures. </td>
            </tr>
             <tr>
              <td>Highly useful for comparing students and for providing quick snapshots of the extent to which learning targets are being met. </td>
              <td>A fundamental aspect of mastery learning approaches (Bloom and Keller) and curriculum-based measurement. </td>
              <td>Has important motivational consequences. Central in individualized approaches to instruction. </td>
            </tr>
          </tbody>
     </table>
</div>

    <div class="single-column">
       <p class="txt"><a class="trigger-readmore" href="#tip6-1" data-type="tipTrigger">Applications: Which Interpretation of Assessment Data Is&nbsp;Needed?</a></p>
    </div>

   <section class="tipBox" id="tip6-1">
      <div class="box-6">
        <h3 class="h3">Applications: Which Interpretation of Assessment Data Is&nbsp;Needed?</h3>
        <p class="txt"><em>Se&ntilde;ora S&aacute;nchez teaches ninth-grade Spanish 1 in an urban high school with an enrollment of 3,000 students. At the end of the year, she gives a final exam to her class. She explains how she interprets the scores:</em> </p>
        <p class="txt">My final exam covers everything we learned in Spanish 1. It has five sections: vocabulary, reading, listening, writing, and speaking. From this test, I can assign a student a grade for the second semester; I can decide what to write in the narrative portion of the grade book; and I can make a recommendation about placement for 10th-grade Spanish (whether or not a student should go to Spanish 2 or Spanish 2 Honors).</p>
        <p class="txt">Here&#39;s how it works: There are 10 questions in each of the five parts of the test for a total of 50 questions. The first 5 questions in each section are from the first semester, and the second 5 are based only on material we covered in the second semester.</p>
        <p class="txt"><em>Semester Grade: </em>To calculate the second semester grade, I use a <em>norm-referenced</em> interpretation of the second 5 items in each section. I rank the students based on their test score and give an A to the students in the top 10%, a B to those in the next 20%, and so on.</p>
        <p class="txt"><em>Narrative Comments: </em>When deciding what to write in the narrative part of the grade book, I use a self-referenced interpretation. To do so, I compare how the student did on the first half of the test (the material from first semester) to performance on the second half. This provides information about each person&#39;s progress over the course of the year.</p>
        <p class="txt"><em>Placement Recommendation: </em>Lastly, I have to decide who is going into regular Spanish 2 and who is ready for Honors&mdash;a criterion-referenced interpretation. For that, I look at the whole test. Because there is usually room for only 30 people in the Honors section, the bar is set really high. As a department, we have decided that unless a student can answer at least 47 of the items correctly, he or she probably isn&#39;t ready for Honors Spanish. Of course, we take other factors into consideration, such as the student&#39;s effort and past performance, but the score on that final exam is a big part of the decision.</p>

 	 <a id="p246"></a>
	 
	 <div class="tbl_scroll_on_mobile">
    <table class="tbl-xl">        
          <thead class="tbl_header">
            <tr>
              <th width="15%">Test section</th>
              <th width="27%">Item numbers used for norm-referenced interpretation of semester grade</th>
              <th width="30%">Item numbers used for self-referenced interpretations</th>
              <th width="27%">Item numbers used for criterion-referenced interpretation of placement</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Vocabulary </td>
              <td>6&ndash;10 </td>
              <td>1&ndash;5 compared to 6&ndash;10 </td>
              <td>1&ndash;10 </td>
            </tr>
            <tr>
              <td>Reading </td>
              <td>16&ndash;20 </td>
              <td>11&ndash;15 compared to 16&ndash;20 </td>
              <td>11&ndash;20 </td>
            </tr>
            <tr>
              <td>Listening</td>
              <td>26&ndash;30 </td>
              <td>21&ndash;25 compared to 26&ndash;30 </td>
              <td>21&ndash;30 </td>
            </tr>
			 <tr>
              <td>Writing </td>
              <td>36&ndash;40 </td>
              <td>31&ndash;35 compared to 36&ndash;40 </td>
              <td>31&ndash;40 </td>
            </tr>
            <tr>
              <td>Speaking</td>
              <td>46&ndash;50 </td>
              <td>41&ndash;45 compared to 46&ndash;50 </td>
              <td>41&ndash;50 </td>
            </tr>
          </tbody>
     </table>
	 </div>

 	</div>
   </section> 
   


	  <div class="single-column">
	      <p class="key-point">No single approach to assessment&mdash;norm-referenced, criterion-referenced, or self-referenced&mdash;is always best. Each one has advantages and disadvantages. </p>
          <p class="txt">In the final analysis, the best approach depends on how the results will be used. As Lok, McNaught, and Young (2016) argue, all three can, and should, be used. Their combined use, they explain, can prevent grade inflation while encouraging alignment between standards and assessments. And used together, they can provide valuable information for placement officers, school administrators, employers, and college admission personnel.</p>
          <p class="txt">Still, some educators strongly recommend one approach over the other. Advocates of criterion-referenced comparisons point to the inherent justice of their approach. No student need fail simply because others learn faster or have less to learn in the first place: All who reach the criterion will be equally successful. </p>
          <p class="txt">Criterion-referenced approaches present a powerful argument for individualizing instruction. And there is strong evidence that when instruction pays attention to individual differences and tailors offerings in response to those differences, it can be highly effective. The most individualized of instructional approaches is one-on-one tutoring. After an extensive review of the literature, Bloom (1984) claimed that an average student paired with a good tutor can be expected to achieve at somewhere around the 98th percentile when compared with a group of similar students taught in a more conventional manner. Criterion-referenced comparisons do, however, have their limitations. For one thing, it is sometimes very difficult to specify the criteria that define acceptable performance or high proficiency. For example, while it might be relatively simple to detail exactly what fourth graders should know and be able to do following a unit on multiplication, it is quite another thing to spell out what they should understand and be able to do following a unit in social studies or religion.</p>

 	 <a id="p247"> </a>
		  <p class="txt">A second limitation of criterion-referenced approaches is that some students are easily able to go beyond established criteria. As we will see in the discussion of competency-based learning (in the next section), some educators fear that this situation might reduce students&#39; motivation and stifle their initiative and creativity.</p>
          <p class="txt">One advantage of norm-referenced approaches is that they provide useful information about the likelihood of success in a competitive, dog-eat-dog kind of world. It isn&#39;t especially surprising that postsecondary admissions are often based largely on the individual&#39;s relative ranking on standardized assessments.</p>
          <p class="txt">Self-referenced interpretations, as we noted, can have important motivational consequences. They can also be useful for setting goals and assessing progress toward those goals. For those who would improve themselves, it is essential to know how they are doing now relative to how they have done in the past (see <em>In the Classroom: A Grading Conundrum</em>).</p>

          <p class="txt"><a class="trigger-readmore" href="#tip6-2" data-type="tipTrigger">In the Classroom: A Grading Conundrum</a></p>
		</div>



   <section class="tipBox" id="tip6-2">
      <div class="box-6">
        <h3 class="h3">In the Classroom: A Grading Conundrum</h3>
        <p class="txt">Imagine you are the fantastic teacher you have always hoped to be. As a result, your students are exceptionally motivated, enormously successful, and deliriously happy. Although your assessments are norm-referenced, the grades you submit to the central office for posting and dissemination are heavily weighted toward the top end of the school&#39;s grading system: Everyone answers almost all your questions correctly, and no one deserves any less than an A.</p>
        <p class="txt">Wonderful situation, isn&#39;t it?</p>
        <p class="txt">But no: Administration says, &quot;Listen, about your grades . . . there&#39;s no spread. We can&#39;t really have that. It&#39;s not like you have only five students! You have 34 in that class. Spread them out. Give us a more reasonable average.&quot;</p>
        <p class="txt">Do you think the opposite might have happened if, despite your unparalleled skills and dedication, all of your students remained pathetically uninterested and appallingly unsuccessful on your tests? Would administration now say, &quot;Hey, listen, about those grades . . . it&#39;s not only that there&#39;s no spread but, well, what&#39;s going on in that class? Do you need some help with your instructional strategies? With your formative assessments? We&#39;re going to have to spread and raise these grades a bit. Give them a more reasonable average.&quot;</p>
        <p class="txt">These scenarios illustrate the conundrum that normative grading can sometimes pose. Yet would the situation always be better if your assessments were based on definite criteria? Consider, for example, a class that uses a competency-based model similar to Bloom&#39;s mastery learning. In this class, students are responsible for mastering a clear progression of skills and are given as much time as they require to reach learning objectives. While they work and study, they have access to various self-tests that allow them to gauge their progress. The final summative examination is given to each learner only when he or she asks for it. In this class, some ask for the test within a few days of starting the unit; others may take weeks. But in the end, all learners receive As.</p>
        <p class="txt">In this scenario, administration is still not very happy with your grades. Should you disagree with them, maintaining that your grades are correct and appropriate? Which grades are more defensible? Those that compare learners to all other learners? Or those that judge them relative to predetermined standards?</p>
 	</div>
   </section> 
   


  </div> 
   <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>



<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.6 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->


<section class="page" id="sec6.6">

 	 <a id="p248"> </a>
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.6</span> <span class="sec_title">Criterion-Based Instructional Systems</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What are some instructional systems based on criterion-referenced comparisons?</span></h2>
  </div>
  <div class="section-lead">
       <p class="intro">Instructional systems based on criterion-referenced approaches are generally referred to as <em>competency-based learning</em> because they are designed to develop competency relative to specific criteria.</p>
   </div>


<div class="section-body">



        <div class="single-column">
		   <p class="key-point">The best known and most widely used of these systems are Benjamin Bloom&#39;s mastery learning and Fred Keller&#39;s <em>Personalized System of Instruction</em>. </p>

          <p class="txt">Several online schools are competency based. Among them are the Florida Virtual School (2018), which provides worldwide schooling from K to 12, and Western Governers University (2018), which is a nonprofit university offering a wide range of courses. Both of these use a competency-based approach to teaching, in which learners can move through the material at their own pace. More time and additional help are available for those who need it. These schools&#39; approaches are heavily based on Bloom&#39;s mastery learning.</p>
       </div>

    <div class="inner-section">
      <h2 class="h2">Bloom&#39;s Mastery Learning</h2>
      <div class="single-column">
      <p class="txt">According to Bloom (1976), most students&mdash;perhaps as many as 90% of them&mdash;can master what schools teach; it is merely a question of how long it will take them, since each student learns at a different pace. Therefore, the main task of educators is to determine how to help their students achieve mastery. Their task is threefold and closely follows the three steps of the backward design model. </p>

      <ol class="nl">
		<li class="li_text">Determine what is meant by mastery. This can be done by establishing standards of competency, then describing specific instructional objectives in terms of actual performances and measurable competencies&mdash;in other words, in terms of criteria.</li>
		<li class="li_text">Devise assessment instruments that will assist learners in mastering instructional objectives (formative assessments) and that will reveal both to learners and to teachers that mastery has been achieved (summative assessment). </li>
		<li class="li_text">Devise instructional strategies that will ensure that most learners achieve mastery.</li>
      </ol>

       <figure class="photo-right-small"><img src="Images/6.3.jpg" alt="Buddhist monk walking along a mountain road." title="Buddhist monk walking along a mountain road." id="img6.3"/>
        <figcaption>
          <p class="cr">Mauritius/Mauritius/SuperStock</p>
          <p class="caption">Determining what is meant by mastery is not always a simple task. For this Buddhist monk traveling to Koh Kho Khao island in Thailand, the criterion of mastery is enlightenment. Our learning targets are less ambitious, although not always a whole lot clearer.</p>
        </figcaption>
      </figure>		  
		  
 	 <a id="p249"> </a>
           <h3 class="h3">Basic Assumptions of Mastery Learning</h3>
		       <p class="txt">One of two basic assumptions underlying Bloom&#39;s model of mastery learning is that most learners can achieve the criteria that define mastery (competence). The second is that achieving mastery requires constant formative assessment&mdash;assessment designed not for grading but directed instead toward helping the student learn.</p>

		       <p class="key-point">Reflecting the first of these two assumptions&mdash;namely, that there are faster and slower learners, but that most, given enough time, can master course objectives&mdash;Bloom&#39;s model of mastery learning holds that degree of learning is a function of the amount of time spent learning relative to the amount of time required. </p>

		       <p class="txt">And the amount of time required is a function not only of ability but also of quality of instruction (see Figure 6.5). As a result, the model attempts to provide all learners with two things:</p>

                <ol class="nl">
		          <li class="li_text">sufficient time to master all important concepts and skills</li>
		          <li class="li_text">the best instructional approaches available</li>
	           </ol>

     </div>

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.5</span><br />
          <span class="figure_title">Bloom&#39;s view of the determinants of degree of learning</span> </h4>
          <p class="caption">In Bloom&#39;s model how much the child learns is a function of time spent versus time needed. Time needed is in turn a function of ability, the effectiveness of instruction, and other factors such as motivation. The examples shown here are hypothetical.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-5" data-type="tipTrigger">
	        <img src="figures/Figure_6.5.jpg" alt="Estimated degree of learning equals the time spent divided by time needed multiplied by 100 to yield a percentage. One of the examples is as follows: If Arnold needs 4 hours to reach criterion X, but only spends two hours studying, his estimated degree of learning is time spent divided by time needed times 100, which equals 2/4 times 100, or 50%." title="Estimated degree of learning equals the time spent divided by time needed multiplied by 100 to yield a percentage. One of the examples is as follows: If Arnold needs 4 hours to reach criterion X, but only spends two hours studying, his estimated degree of learning is time spent divided by time needed times 100, which equals 2/4 times 100, or 50%." id="fig_6.5"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-5">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.5.jpg" alt="Estimated degree of learning equals the time spent divided by time needed multiplied by 100 to yield a percentage. One of the examples is as follows: If Arnold needs 4 hours to reach criterion X, but only spends two hours studying, his estimated degree of learning is time spent divided by time needed times 100, which equals 2/4 times 100, or 50%." title="Estimated degree of learning equals the time spent divided by time needed multiplied by 100 to yield a percentage. One of the examples is as follows: If Arnold needs 4 hours to reach criterion X, but only spends two hours studying, his estimated degree of learning is time spent divided by time needed times 100, which equals 2/4 times 100, or 50%." id="fig_6.5"/>
 	  </div>
   </section>



      <div class="single-column">
	 <a id="p250"> </a>
       <h3 class="h3">Characteristics of Mastery Learning</h3>
          <p class="txt">The instructional method that Bloom developed based on these considerations has a number of important characteristics. </p>

          <p class="key-point">First, it is directed toward mastering course or unit objectives. </p>

          <p class="txt">Bloom believed that any learning sequence can be broken down into sequential steps and clear objectives so that most, if not all, learners can reach them. </p>

          <p class="key-point">Second, Bloom&#39;s approach to instruction also makes extensive use of formative evaluation. </p>

          <p class="txt">At every step in the learning sequence, the learner takes one or more mastery quizzes. Progress to the next step in the sequence requires mastery of earlier steps. Mastery quizzes sometimes take the form of computer-adaptive testing, in which computers are programmed to modify their presentation of test items based on learner responses. When adaptive testing is used in mastery learning, the computer is programmed to determine whether the learner has achieved a criterion of mastery. Following a study involving more than 12,500 Australian elementary and secondary school students, Martin and Lazendic (2018) provide evidence that computer-adaptive mastery testing can be highly efficient and effective and can have positive effects on student motivation and engagement. </p>

          <p class="key-point">Third, mastery learning requires the use of a wide variety of corrective procedures guided by ongoing formative evaluation. </p>

          <p class="txt">While many of these corrective procedures will make use of traditional approaches to teaching, a variety of other classroom activities are highly recommended. These include study sessions, individualized tutoring, reviewing, cooperative group approaches, and a wide variety of instructional materials and different media. Also, advances in artificial intelligence have made possible the development of <em>intelligent tutor systems</em> that adjust their offerings in line with learner understanding and progress. Adaptive learning software of this kind is especially well suited for competency-based learning systems such as Bloom&#39;s (Nasserghodsi, 2017).</p>

          <p class="key-point">Fourth, Bloom suggests that all learners should progress from one unit to the next as a group. </p>

          <p class="txt">This is accomplished by providing additional enrichment for those who are first to master course or unit objectives. As a result, progress occurs at the rate of the slowest learners. All students who master course objectives are given an A; those who don&#39;t are given an I (for incomplete). Figure 6.6 summarizes the main assumptions and features of Bloom&#39;s mastery learning.</p>
 	 </div>

	 <a id="p251"></a>
    
   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.6</span><br />
          <span class="figure_title">Basic assumptions and characteristics of mastery learning</span> </h4>
          <p class="caption">The basic elements of Bloom&#39;s mastery learning emphasize its reliance on criterion-referenced formative and summative assessment.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-6" data-type="tipTrigger">
	        <img src="figures/Figure_6.6.jpg" alt="Main assumptions of the mastery of learning are that there are faster learners and slower learners and that learning requires constant formative evaluation to guide the teaching&ndash;learning process. The practical implications are that learners must be provided with as much time as required to master sequentially ordered competencies and that teachers need to develop criterion-referenced quizzes and tests to gauge learning progressions and assist learners. The broad characteristics of teaching methods are that content is divided into small, sequential units. Instruction is directed toward specific targets describable in terms of measurable criteria. Also, formative evaluation is accompanied by various instructional procedures, including individual study sessions, cooperative approaches, tutoring, reteaching, and so on." title="Main assumptions of the mastery of learning are that there are faster learners and slower learners and that learning requires constant formative evaluation to guide the teaching&ndash;learning process. The practical implications are that learners must be provided with as much time as required to master sequentially ordered competencies and that teachers need to develop criterion-referenced quizzes and tests to gauge learning progressions and assist learners. The broad characteristics of teaching methods are that content is divided into small, sequential units. Instruction is directed toward specific targets describable in terms of measurable criteria. Also, formative evaluation is accompanied by various instructional procedures, including individual study sessions, cooperative approaches, tutoring, reteaching, and so on." id="fig_6.6"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-6">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.6.jpg" alt="Main assumptions of the mastery of learning are that there are faster learners and slower learners and that learning requires constant formative evaluation to guide the teaching&ndash;learning process. The practical implications are that learners must be provided with as much time as required to master sequentially ordered competencies and that teachers need to develop criterion-referenced quizzes and tests to gauge learning progressions and assist learners. The broad characteristics of teaching methods are that content is divided into small, sequential units. Instruction is directed toward specific targets describable in terms of measurable criteria. Also, formative evaluation is accompanied by various instructional procedures, including individual study sessions, cooperative approaches, tutoring, reteaching, and so on." title="Main assumptions of the mastery of learning are that there are faster learners and slower learners and that learning requires constant formative evaluation to guide the teaching&ndash;learning process. The practical implications are that learners must be provided with as much time as required to master sequentially ordered competencies and that teachers need to develop criterion-referenced quizzes and tests to gauge learning progressions and assist learners. The broad characteristics of teaching methods are that content is divided into small, sequential units. Instruction is directed toward specific targets describable in terms of measurable criteria. Also, formative evaluation is accompanied by various instructional procedures, including individual study sessions, cooperative approaches, tutoring, reteaching, and so on." id="fig_6.6"/>
 	  </div>
   </section>


	</div>

   <h2 class="h2">Keller&#39;s Personalized System of Instruction </h2>
    <div class="single-column">
          <p class="txt">Keller&#39;s (1968) <strong>Personalized System of Instruction (PSI)</strong> is another competency-based approach to teaching and learning. Originally designed as an approach to classroom teaching, PSI has since been used extensively in distance education and computer-based courses. </p>
          <p class="key-point">Unlike Bloom&#39;s mastery learning, which is designed for use with groups of learners, PSI was intended for individual instruction. </p>
          <p class="txt">Keller first developed PSI for teaching introductory psychology, but it has since been used in a variety of other courses (e.g., Paiva, Ferreira, &amp; Frade, 2017; Viness, Colquitt, Pritchard, &amp; Johnson, 2017).</p>
          <p class="txt">Like Bloom&#39;s mastery learning, PSI requires that (a) course material be broken down into small units, (b) students be given as much time as necessary to master each unit, and (c) criterion-referenced tests be developed to gauge learner progress. At the end of the unit, learners are given a test that covers all the material. In PSI, units are often entire chapters of textbooks.</p>

	 <a id="p252"></a>
          <p class="txt">Unlike Bloom&#39;s mastery learning, PSI does not use traditional teaching methods such as lecturing or presenting lessons. </p>
          <p class="key-point">Instead, the emphasis is on the written word. </p>
          <p class="txt">As Paiva and colleagues (2017) explain, in PSI, instructors typically prepare a written study guide containing objectives and questions. The guide outlines precisely what students should do and what they should learn. Progress through the course is self-paced, and course presentation is written rather than teacher presented. Another difference between Bloom&#39;s mastery learning and PSI is that PSI does not make extensive use of remedial materials. Instead, students are largely responsible for their own learning. Student (peer) tutors are closely involved, and in many cases they are responsible for administering and marking unit quizzes.</p>
          <p class="txt">In many applications of PSI, computers are used extensively. In fact, PSI is increasingly being used as the basis for developing an ITS (e.g. Paiva et al., 2017). The main elements of PSI can be summarized as follows:</p>


	     <ul class="bl">
              <li class="li_text">Instruction is directed toward mastery.</li>
              <li class="li_text">Objectives to be mastered are clearly specified.</li>
              <li class="li_text">Instructional systems are self-paced and largely individual.</li>
              <li class="li_text">Instruction is based mainly on the written word (chapters rather than lectures).</li>
              <li class="li_text">Material is carefully sequenced in small subunits.</li>
			  <li class="li_text">Unit mastery is required before moving on.</li>
              <li class="li_text">Repeated testing is employed.</li>
              <li class="li_text">Proctors (peer tutors) are used to help learners and to administer tests.</li>
              <li class="li_text">The emphasis is on reward for success rather than penalties for errors.</li>
              <li class="li_text">Lectures are used for motivation, as a reward.</li>
      </ul>

	</div>

</div>
<script type="text/javascript" src="Scripts/app-min.js"></script>
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.7 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->



<section class="page" id="sec6.7">
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.7</span> <span class="sec_title">Applications of Competency-Based Approaches</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What are the advantages and disadvantages of competency-based approaches?</span></h2>
  </div>
  <div class="section-lead">     
	   <p class="intro">There is evidence that competency-based approaches to education can lead to highly positive attitudes among learners. </p>
   </div>


<div class="section-body">
    <div class="single-column">
	      <p class="txt">For example, Foss, Foss, Paynton, and Hahn (2014) implemented a PSI program in eight college courses. An intensive case study of two of these courses showed markedly decreased dropout rates. </p>
          <p class="txt">There is evidence, too, that PSI approaches can be very effective in helping learners reach course goals. Paiva and colleagues (2017) developed a college-level ITS mathematics program. Use of this program was found to result in significant improvement in student achievement and engagement in the course. Similarly, Prewitt and associates (2015) used a PSI system with secondary school students in a 6-week unit on physical fitness. Comparisons of a PSI group of students with a second group that had been presented with the same material in a conventional classroom setting showed significantly higher levels of health-related fitness knowledge among the PSI group.</p>

	 <a id="p253"></a>
		  <p class="txt">Based on several meta-analyses of competency-based approaches to learning (basically, a form of research that summarizes a large group of related studies), Zimmerman and Dibenedetto (2008) conclude: &quot;The effectiveness of mastery learning approaches has been documented in numerous studies&quot; (p. 209). </p>
          <p class="txt">In spite of the effectiveness of these competency-based approaches, they have not been very widely adopted. There are several reasons for this: One is that these systems require a dramatic change in the teacher&#39;s role. Teachers become facilitators rather than primary sources of instruction and information. And they become administrators who are charged with recruiting, organizing, and overseeing proctors&mdash;which is not always an easy task.</p>
          <p class="txt">Another reason competency-based approaches are not highly popular is the fear that they might lead to boredom among the faster learners. Critics argue that emphasis on objectives that all learners can master might destroy motivation and render the assignment of grades meaningless and nonreinforcing. If all who work long enough get As, there is perhaps little incentive to work hard and finish first. Furthermore, claim the critics, restricting instructional emphases to simple, identifiable objectives might prevent the occurrence of important incidental learning. </p>
          <p class="txt">Perhaps the most important reason competency-based approaches are not more popular, despite their demonstrated effectiveness, is they are not easy to develop: They require an enormous expenditure of time and effort by the teacher&mdash;and a fair allotment of intelligence as well. But given the demonstrated effectiveness of competency-based approaches, Foss and colleagues (2014) suggest that although PSI &quot;largely died out after its peak in the 1970s, [it] may deserve a second look as an effective method for retaining and graduating college students&quot; (p. 1).</p>
    </div>
	
 </div> 
 <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>



<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.8 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->



<section class="page" id="sec6.8">
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.8</span> <span class="sec_title">Planning for Summative Assessment</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Questions</span> <span class="focus_q">What are the six questions teachers should ask themselves when planning for summative assessment? <br/>Why are they useful?</span></h2>
  </div>
  <div class="section-lead">     
	   <p class="intro">During a preschool, school, and postsecondary educational career, student achievement will be gauged and summed in a huge variety of ways and at many different times.</p>
  </div>

<div class="section-body">
    <div class="single-column">
	      <p class="txt">Here are just a few examples:</p>

		  	<ul class="bl">
			  <li class="li_text">end-of-unit or end-of-chapter tests</li>
			  <li class="li_text">end-of-term or end-of-year tests</li>
			  <li class="li_text">state assessments</li>
			  <li class="li_text">district-wide benchmark or achievement tests</li>
			  <li class="li_text">all assessment procedures used for calculating grades</li>
			  <li class="li_text">assessment procedures used as measures of school and teacher accountability</li>
			  <li class="li_text">a variety of professionally prepared high-stakes achievement tests </li>       
           </ul>

	 <a id="p254"></a>
          <p class="txt">Summative assessments can take many different forms. Often assessments will involve the evaluation of written, keyboard, or touch-screen responses to teacher-made tests, standardized tests, or other district, state, or even national assessments. Some assessments may require the learner to <em>do</em> or <em>perform</em> in ways that do not require written responses&mdash;termed <em>performance-based assessment</em>. Other assessments might involve rubrics or various kinds of checklists, demonstrations, performances, or collections of samples of student accomplishments (termed <strong>portfolios</strong>)&mdash;or a variety of other indicators of development and achievement. Chapter 7 focuses on these different approaches to performance-based assessment.</p>
          <p class="key-point">Planning for summative assessment should begin well before the start of instruction. </p>
          <p class="txt">In fact, as the <em>backward design</em> approach to curriculum development suggests, planning for assessment should flow directly from the goals of the educational system; it should be developed prior to planning for instruction. </p>
          <p class="txt">Developing an appropriate and systematic plan for summative assessment requires that teachers answer a sequence of questions similar to those provided here. </p>

    </div>
	

    <div class="inner-section">
      <h2 class="h2">1. What Should My Students Learn?</h2>
      <div class="single-column">
          <p class="txt">It all originates with a clear statement of instructional objectives: What will students learn? What skills, values, attitudes, and understanding will they develop? </p>
          <p class="txt">Clearly, instructional objectives are not entirely the prerogative of the classroom teacher. Mr. Smithers, a third-grade teacher, is not likely to be told, &quot;Well, Smithers, why don&#39;t you go ahead and decide what your third graders should learn in arithmetic this year?&quot; No. There are usually curriculum requirements&mdash;that is, state-determined standards&mdash;that specify what third graders should know. For example, among the CCSS for mathematics developed by the CCSSO (2018) is the statement that third graders should be able to </p>
          <p class="ext">interpret products of whole numbers, e.g., interpret 5 &times; 7 as the total number of objects in 5 groups of 7 objects each. For example, describe a context in which a total number of objects can be expressed as 5 &times; 7. </p>
          <p class="txt">Statements of these standards also include sample test items (see Figure 6.7). These can be used as a basis for generating items for both summative and formative assessments.</p>
     </div>

	 <a id="p255"></a>
    
   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.7</span><br />
          <span class="figure_title">Sample items for one common core standard, third-grade mathematics</span> </h4>
          <p class="caption">The CCSS developed by the National Governors Association Center for Best Practices and the CCSSO list dozens of standards for each grade level. These define academic expectations in English language arts and mathematics. In many states these are the basis for standardized summative assessments.</p>
		  <p class="src">Reprinted by permission of The NGA Center for Best Practices (NGA Center) and the Council of Chief State School Officers. &copy; Copyright 2010. National Governors Association Center for Best Practices and Council of Chief State School Officers. All rights reserved.</p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-7" data-type="tipTrigger">
	        <img src="figures/Figure_6.7.jpg" alt="Sample includes Standard 3, third-grade mathematics: Multiply one-digit whole numbers by multiples of 10 in the range 10&ndash;90 using strategies based on place value and properties of operations. There are questions such as: Which number&#39;s underlined digit is worth 8? In 698, which number is in the hundreds place? Multiply: 7 x 50." title="Sample includes Standard 3, third-grade mathematics: Multiply one-digit whole numbers by multiples of 10 in the range 10&ndash;90 using strategies based on place value and properties of operations. There are questions such as: Which number&#39;s underlined digit is worth 8? In 698, which number is in the hundreds place? Multiply: 7 x 50." id="fig_6.7"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-7">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.7.jpg" alt="Sample includes Standard 3, third-grade mathematics: Multiply one-digit whole numbers by multiples of 10 in the range 10&ndash;90 using strategies based on place value and properties of operations. There are questions such as: Which number&#39;s underlined digit is worth 8? In 698, which number is in the hundreds place? Multiply: 7 x 50." title="Sample includes Standard 3, third-grade mathematics: Multiply one-digit whole numbers by multiples of 10 in the range 10&ndash;90 using strategies based on place value and properties of operations. There are questions such as: Which number&#39;s underlined digit is worth 8? In 698, which number is in the hundreds place? Multiply: 7 x 50." id="fig_6.7"/>
 	  </div>
   </section>



       <div class="single-column">
         <p class="txt">Unfortunately, statements of statewide (common) standards do not always simplify matters very much. For example, the sample standard given in Figure 6.7 is just one of dozens of different standards intended to serve as guides for instructional objectives. In addition, these many standards are each linked to a variety of specific skills. As Marzano (2000) notes, lists of educational standards and instructional objectives have many problems. Here are some of them.</p>

       	   <ul class="bl">
              <li class="li_text">There are often too many standards listed. Interpreting and using them becomes confusing and difficult.</li>
              <li class="li_text">Many standards are overly ambitious: They represent lofty but unrealistic ideals.</li>
              <li class="li_text">Overadherence to standards can be restrictive for teachers, constraining their instructional approaches and limiting the spontaneity and creativity of their efforts.</li>
              <li class="li_text">Some prescribed standards make excessive and difficult demands on learners.</li>
              <li class="li_text">Standards-based curricula and assessment have led to what many consider to be the overuse of testing and, indirectly, to some of the negative implications of high-stakes testing (see Chapter 10).</li>
           </ul>

	 <a id="p256"></a>
		  <p class="txt">These criticisms and problems, however, do not apply to all uses of educational standards. There is little doubt that clear instructional objectives are absolutely fundamental to good educational assessment. And statewide standards can go a long way toward making schools and teachers more accountable and can ultimately improve teaching and learning.</p>
       </div>
    </div>

     <h2 class="h2">2. How Can I Backward Design Assessment and Instruction?</h2>
      <div class="single-column">
          <p class="txt">Clarifying educational goals and specifying learning objectives is the first important step in the <em>backward design</em> approach. The next is to decide what approaches to assessment will be most useful in determining whether learners have reached (or are reaching) these goals. Finally, the teacher plans instructional approaches. This careful planning is important for bringing instructional methods into alignment with assessment and with instructional objectives. The process provides answers for these important questions: What should my students know/be able to do/understand? What sorts of informal and formal assessment will I use for formative purposes <em>during</em> instruction? How will I measure what they have achieved after instruction? How can I help learners reach learning objectives? What teaching and learning approaches are most appropriate for this content? For these instructional objectives? For this group of learners? For each learner in my class?</p>
	  </div>




    <div class="inner-section">
      <h2 class="h2">3. How Will I Know Learning Has Occurred?</h2>
      <div class="single-column">
         <p class="txt">Being aware of the progression of student learning and, in the end, knowing how well they have learned are fundamental to good instruction. Some important considerations should be kept in mind when planning for assessment.</p>

        <ul class="bl">
        <li class="li_text">Most important, emphasis should be placed on assessments that are most likely to enhance learning. That is, the formative rather than the summative functions of assessment are most important.</li>
        <li class="li_text">Care should be taken to use approaches to assessment that are interesting, meaningful, and motivating for the 21st-century learner. Recall that, as we saw in Chapter 3, this learner is of the net generation, reared with computers, video games, the Internet, social media, and wireless technology. Some of the educationally important identifying characteristics of many&mdash;though clearly not all&mdash;of today&#39;s learners are summarized in Figure 6.8. </li>
        <li class="li_text">Assessments should be closely aligned with instructional objectives. For example, if instructional objectives have more to do with higher order thinking skills than with the learning of specific facts, assessments should not require learners to reproduce verbatim chunks of information.</li>
       </ul>
     </div>

	 <a id="p257"></a>
    
   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.8</span><br />
          <span class="figure_title">Some educationally relevant common characteristics of today&#39;s learner</span> </h4>
          <p class="caption">Although these descriptions are not characteristics of all today&#39;s learners, they are common enough to be tremendously important for those teachers who want to excel. Increasingly, effective teaching depends on the skilled use and understanding of educational technology.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-8" data-type="tipTrigger">
	        <img src="figures/Figure_6.8.jpg" alt="Circle labeled &quot;Today&#39;s learners are used to receiving information extraordinarily rapidly from a variety of high-impact, colorful, multimodal, high-interest sources. As a result, they may...&quot; This circle has arrows pointing to seven circles surrounding it, each with a phrase that finishes the sentence. For example, &quot;... be more independent and less authority oriented.&quot;" title="Circle labeled &quot;Today&#39;s learners are used to receiving information extraordinarily rapidly from a variety of high-impact, colorful, multimodal, high-interest sources. As a result, they may...&quot; This circle has arrows pointing to seven circles surrounding it, each with a phrase that finishes the sentence. For example, &quot;... be more independent and less authority oriented.&quot;" id="fig_6.8"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-8">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.8.jpg" alt="Circle labeled &quot;Today&#39;s learners are used to receiving information extraordinarily rapidly from a variety of high-impact, colorful, multimodal, high-interest sources. As a result, they may...&quot; This circle has arrows pointing to seven circles surrounding it, each with a phrase that finishes the sentence. For example, &quot;... be more independent and less authority oriented.&quot;" title="Circle labeled &quot;Today&#39;s learners are used to receiving information extraordinarily rapidly from a variety of high-impact, colorful, multimodal, high-interest sources. As a result, they may...&quot; This circle has arrows pointing to seven circles surrounding it, each with a phrase that finishes the sentence. For example, &quot;... be more independent and less authority oriented.&quot;" id="fig_6.8"/>
 	  </div>
   </section>



    </div>


    <h2 class="h2">4. How Will Assessment Be Conducted and Used?</h2>
       <div class="single-column">
         <p class="txt">Planning for assessment requires that the teacher decide beforehand what sorts of assessment methods to use as well as how assessment information will be gathered, how often assessments will occur, and when they will take place. Ideally, the teacher should now prepare a written assessment plan for the unit, term, or course that is to be assessed. This plan should contain information that reflects answers to many of the questions listed in this section, relating to</p>

	 <a id="p258"></a>
		 	<ul class="bl">
              <li class="li_text">the most important instructional objectives for the assessment period,</li>
              <li class="li_text">the nature of the evidence that will be used to determine progress and achievement relative to these targets, and</li>
              <li class="li_text">how assessment might be used to improve teaching and learning. </li>
          </ul>
		   
		  <p class="txt">An example of a general assessment plan for a phonics unit in early reading instruction is shown in Figure 6.9.</p>

       </div>
    
   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.9</span><br />
          <span class="figure_title">Sample assessment plan</span> </h4>
          <p class="caption">Assessment plans might cover a single unit of instruction, as shown here. Or they might be developed for an entire term or course. Where a variety of tests and quizzes are used, and where assessments also include other information and indicators such as class participation, improvement, homework, class assignments, and so on, the nature and weighting of these contributors would also be included in the assessment plan.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-9" data-type="tipTrigger">
	        <img src="figures/Figure_6.9.jpg" alt="Chart outlines the assessment plan for first-grade reading program: Building reading skills: Phonics target. It is broken up into five parts: Unit 1 learning target: Basic phonics: Letter and word recognition; Instructional time period; Formative assessment; Summative assessment; and Grading." title="Chart outlines the assessment plan for first-grade reading program: Building reading skills: Phonics target. It is broken up into five parts: Unit 1 learning target: Basic phonics: Letter and word recognition; Instructional time period; Formative assessment; Summative assessment; and Grading." id="fig_6.9"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-9">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.9.jpg" alt="Chart outlines the assessment plan for first-grade reading program: Building reading skills: Phonics target. It is broken up into five parts: Unit 1 learning target: Basic phonics: Letter and word recognition; Instructional time period; Formative assessment; Summative assessment; and Grading." title="Chart outlines the assessment plan for first-grade reading program: Building reading skills: Phonics target. It is broken up into five parts: Unit 1 learning target: Basic phonics: Letter and word recognition; Instructional time period; Formative assessment; Summative assessment; and Grading." id="fig_6.9"/>
 	  </div>
   </section>


    <div class="inner-section">
	 <a id="p259"></a>
      <h2 class="h2">5. How Can I Ensure Validity, Fairness, and Reliability of My Assessments?</h2>
      <div class="single-column">
          <p class="txt">Recall from Chapter 2 that an assessment is valid not only when it measures what it is intended to measure but, more importantly, when the interpretations and uses to which it is put are supported by evidence. It is reliable when it measures consistently and as accurately as possible. And it is fair when it is free from biases, assesses instructional objectives that all learners have had an opportunity to reach, gives test takers sufficient time, and accommodates special needs as required.</p>

          <p class="txt">Teachers can increase the validity and reliability of their measures in several ways. We know, for example, that using test blueprints (tables of specifications) of the kind described and illustrated in Chapter 2 can do much to ensure that assessment items are aligned with instructional objectives. Assessments that are not well aligned with instructional objectives are less likely to be valid measures of those targets. (Chapters 4 and 8 also present more information about test blueprints, along with some illustrative samples.)</p>

          <p class="txt">Test reliability is affected by several factors.</p>

		  	<ul class="bl">
              <li class="li_text">The length of tests: In general, tests consisting of more items tend to be more reliable than those with fewer items.</li>
              <li class="li_text">The stability of a characteristic: Measures of characteristics that fluctuate are often inconsistent, and therefore measurements of such characteristics will by definition be unreliable.</li>
              <li class="li_text">Item difficulty: Tests containing moderately difficult items tend to be more reliable than tests that contain very difficult or extraordinarily easy items.</li>
          </ul>

	  </div>
	</div>


    <h2 class="h2">6. How Will I Calculate and Report Summative Assessment Results?</h2>
     <div class="single-column">
         <p class="txt">Finally, the teacher needs to answer questions relating to how the results of summative assessment are to be calculated and reported: What role will the teacher&#39;s professional judgment play in the final assessment? What provision is there for reconciling dramatic differences between end-of-unit or end-of-term results and performance during the term? In what form will results be communicated to those who have a right to know (usually students, parents or guardians, and educational personnel)? These are questions that we will look at in detail in Chapter 11. </p>

          <p class="txt">Figure 6.10 summarizes the decision-making sequence involved in planning for summative assessment. Given the often significant and long-term implications of the results of summative assessments, asking and answering each of the questions shown in Figure 6.10 is hugely important.</p>

       </div>

	<a id="p260"></a>

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.10</span><br />
          <span class="figure_title">Planning for summative assessment</span> </h4>
          <p class="caption">Planning for summative assessment should begin before instruction and requires not only answering each of these questions&mdash;and others&mdash;but implementing the answers.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-10" data-type="tipTrigger">
	        <img src="figures/Figure_6.10.jpg" alt="Circle with six circles surrounding it. The center circle, labeled &quot;Questions to answer when planning summative assessment,&quot; has an arrow pointing to another circle, labeled &quot;1. What should my students learn?&quot; An arrow moves from this circle to the next circle, and onward to each circle surrounding the circle in the center. Each circle has a numbered step with a question that should be answered." title="Circle with six circles surrounding it. The center circle, labeled &quot;Questions to answer when planning summative assessment,&quot; has an arrow pointing to another circle, labeled &quot;1. What should my students learn?&quot; An arrow moves from this circle to the next circle, and onward to each circle surrounding the circle in the center. Each circle has a numbered step with a question that should be answered." id="fig_6.10"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-10">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.10.jpg" alt="Circle with six circles surrounding it. The center circle, labeled &quot;Questions to answer when planning summative assessment,&quot; has an arrow pointing to another circle, labeled &quot;1. What should my students learn?&quot; An arrow moves from this circle to the next circle, and onward to each circle surrounding the circle in the center. Each circle has a numbered step with a question that should be answered." title="Circle with six circles surrounding it. The center circle, labeled &quot;Questions to answer when planning summative assessment,&quot; has an arrow pointing to another circle, labeled &quot;1. What should my students learn?&quot; An arrow moves from this circle to the next circle, and onward to each circle surrounding the circle in the center. Each circle has a numbered step with a question that should be answered." id="fig_6.10"/>
 	  </div>
   </section>


     
	 <div class="single-column">
          <p class="txt">But asking and answering the questions may not be the most difficult part of the task: Implementing the answers might pose the biggest challenges. </p>
          <p class="txt">In addition to asking these questions, planning for assessment often involves generating or finding appropriate test items and instruments for the more formal aspects of assessment. Some of these will be teacher constructed (discussed in Chapter 8); others will be commercially prepared. Some commercially prepared tests consist of items produced to accompany and be closely aligned with a specific text or curriculum; others might be standardized tests developed to gauge the extent to which learners have reached state-defined standards. Standardized tests are discussed in Chapter 10.</p>
          <p class="txt">The next two sections look at two other approaches to educational assessment: curriculum-based measurement and benchmark testing. These approaches are especially useful for gauging progress through a curriculum and for monitoring the extent to which course content is being mastered. </p>

       </div>

  </div> 
<script type="text/javascript" src="Scripts/app-min.js"></script>  
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.9 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->



<section class="page" id="sec6.9">
	<a id="p261"></a>
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.9</span> <span class="sec_title">Curriculum-Based Measurement</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What is curriculum-based measurement?</span></h2>
  </div>

  <div class="section-lead">     
	   <p class="intro">Closely related to the criterion-referenced mastery testing advocated by Bloom and Keller is an approach labeled <strong>curriculum-based measurement (CBM)</strong>, also referred to as <em>curriculum-based assessment</em> or <em>CBA</em>. </p>
      </div>


<div class="section-body">
    <div class="single-column">
	  <p class="txt">Although this chapter deals primarily with summative assessment, CBM is often used more as a formative than a summative measure. However, because of its usefulness in competency-based learning, it is discussed here. In addition, CBM has been shown to provide useful summative measures for predicting future performance (Van Norman &amp; Parker, 2018). </p>
    </div>
     	 
	 <figure class="photo-right"><img src="Images/6.4.jpg" alt="Children playing xylophones." title="Children playing xylophones." id="img6.4"/>
        <figcaption>
          <p class="cr">Hero Images/SuperStock</p>
          <p class="caption">CBM focuses on basic skills and knowledge tied directly to the curriculum. It is most common in core subject areas. Some fear that with increasing emphasis on <em>common core standards</em>, subjects such as art, drama, physical education, and&mdash;much to the disappointment of these children&mdash;music will increasingly be ignored.</p>
        </figcaption>
      </figure>

 
   <div class="single-column">
          <p class="key-point">As the label implies, CBM attempts to measure basic skills and knowledge that are tied directly to the curriculum. </p>
          <p class="txt">CBM is most common in core subject areas such as language arts and mathematics. It is designed mainly to provide information about how students are progressing. Accordingly, CBM measures often occur during an instructional sequence, when they provide information about learner progress and responses to intervention. </p>
          <p class="txt">Curriculum-based assessments generally consist of a small selection of tasks or problems that are actually part of the curriculum. The learner&#39;s performance on these serves as a direct indicator of progress. For example, a CBM measure in arithmetic might present the learner with four or five problems that closely reflect the curriculum being taught. In an early reading program, a CBM assessment might count the number of words the learner reads correctly in a fixed period of time. Following a series of such assessments, the teacher can plot the results to provide a graphic representation of learner progress.</p>
   </div>
 
    
    <div class="inner-section">
      <h2 class="h2">CBM Probes</h2>
      <div class="single-column">
	  <p class="txt">CBM measures are sometimes developed by classroom teachers, but they are also widely available commercially in the form of what are often termed <strong>CBM probes</strong>. In their commercialized form, these assessments are given under standardized conditions: They are timed, use consistent instructions, and are marked according to predetermined procedures. Performance is typically scored for speed and accuracy. CBM measures are usually given frequently and serve as an indicator of student progress and as a source of guidance for both instruction and learning.</p>

	<a id="p262"></a>
	  <p class="txt">CBM probes are usually very brief series of questions, test items, or performances that can be administered in a few minutes. The most common CBM probes have been developed for curriculum areas such as arithmetic, spelling, reading, and writing. For example, CBM probes in mathematics might consist of work sheets that tap single skills (such as adding two-digit numbers), or they might be probes that look at a variety of skills (such as addition and multiplication). Figure 6.11 presents an example of a single-skill mathematics CBM probe.</p>
     </div>
          

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.11</span><br />
          <span class="figure_title">Example of a single-skill teacher-made CBM math probe</span> </h4>
          <p class="caption">CBM presents brief, commercially prepared or teacher-made <em>probes</em> designed to assess the extent to which learners are developing skills and understanding related directly to the curriculum. In addition to its use as an indication of progress (a <em>summative</em> function), CBM provides feedback that can be useful for teaching and learning (a <em>formative</em> purpose).</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-11" data-type="tipTrigger">
	        <img src="figures/Figure_6.11.jpg" alt="Example includes the following text: &quot;Second-grade students are asked to add as many of the following pairs of single-digit numbers as they can in one minute.&quot; There are eight simple math problems to be solved." title="Example includes the following text: &quot;Second-grade students are asked to add as many of the following pairs of single-digit numbers as they can in one minute.&quot; There are eight simple math problems to be solved." id="fig_6.11"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-11">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.11.jpg" alt="Example includes the following text: &quot;Second-grade students are asked to add as many of the following pairs of single-digit numbers as they can in one minute.&quot; There are eight simple math problems to be solved." title="Example includes the following text: &quot;Second-grade students are asked to add as many of the following pairs of single-digit numbers as they can in one minute.&quot; There are eight simple math problems to be solved." id="fig_6.11"/>
 	  </div>
   </section>
    </div>
   
   <h2 class="h2">Uses and Advantages of CBM Measures</h2>
   <div class="single-column">
         <p class="txt">An important advantage of CBM measures over other standardized norm-referenced assessments is that they are tied more closely to the school&#39;s curriculum. Because test makers want the largest possible number of users, most standardized tests are normed using national samples of individuals and curriculum content. As a result, some standardized tests might be a poor match for a district or state curriculum.</p>
          <p class="txt">Other advantages of CBM measures are that they can be administered quickly, often in just a few minutes. And because they can be given often, they are highly sensitive to short-term gains or declines. Accordingly, they can provide useful information about changes in learners as well as about the effectiveness of instructional procedures. Not surprisingly, CBM probes have been widely used by teachers of children with special needs (Jenkins, Schulze, Marti, &amp; Harbaugh, 2017). They have proved very useful for assessing learning problems and for helping students who have been performing less well than expected (Allen, Poch, &amp; Lembke,&nbsp;2018).</p>
   </div>


  </div> 
  <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>


<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.10 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->



<section class="page" id="sec6.10">
	<a id="p263"></a>
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.10</span> <span class="sec_title">Benchmark Assessment</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What is benchmark measurement?</span></h2>
  </div>

  <div class="section-lead">     
	   <p class="intro">CBM measurement is typically a recurring, classroom-based form of assessment that occurs during instruction and that is designed to provide a picture of student progress toward specified goals that are often explicit in statewide standards. It is basically a form of what is widely referred to as <strong>benchmark assessment</strong>.</p>
      </div>


<div class="section-body">
    <div class="single-column">
        <p class="txt">Literally, a benchmark is a standard of excellence or achievement that provides a basis for comparing and judging something. Accordingly, benchmark assessment in education is a way of comparing achievement to some standard. Benchmark assessments are quite different from annual statewide tests, whose main purpose is determining to what extent mandated standards have been met. Statewide tests are typically given at the end of an instructional sequence.</p>
    </div>
     
    <div class="inner-section">
      <h2 class="h2">Uses of Benchmark Assessments</h2>
      <div class="single-column">
	  <p class="txt">Although benchmark tests are most often administered at regular intervals during a course or a term, they may be administered prior to instruction or at the end of a unit or even a school year. For example, Hornack (2016) reports a study in which benchmark assessments in mathematics were administered to first-, second-, and third-grade students at the end of the school year. The same assessments were given to the same students again, approximately two months later at the very beginning of the next school year. Some of the schools involved in this study had a traditional 12-week summer vacation; others operated with a <em>balanced</em> school year that had a 6-week vacation period. This use of benchmark assessment at both the end and the beginning of the school year provided a dramatic illustration of the amount of mathematical knowledge that is typically lost over a summer. And the evidence suggests that the longer the summer break, the greater the loss (see Figure 6.12). </p>
     </div>

	<a id="p264"></a>

   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.12</span><br />
          <span class="figure_title">Loss of math knowledge and skills during summer vacation</span> </h4>
          <p class="caption">Benchmark assessments given to first-, second-, and third-grade students at the beginning and end of summer vacation reveal dramatic losses in math knowledge. The greatest loss is associated with the longer, more traditional summer vacation.</p>
		  <p class="src">Based on data from &quot;Impact of Summer Recess on Mathematics Learning Retention,&quot; by D. Hornack, 2016, <span class="no_italic">Education Leadership Review of Doctoral Research, 3,</span> pp. 37&ndash;45.</p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-12" data-type="tipTrigger">
	        <img src="figures/Figure_6.12.jpg" alt="Bar graph showing that loss of mathematical knowledge for first-, second-, and third-grade students over the summer period is greater when the vacation period is longer. Students who had just a 6-week vacation lost very little knowledge as measured by a benchmark test (a score of 42.88 at the beginning of the vacation dropped to 40.11 after 6 weeks). In contrast, students who had a 12-week vacation dropped from a score of 41.94 to 34.03." title="Bar graph showing that loss of mathematical knowledge for first-, second-, and third-grade students over the summer period is greater when the vacation period is longer. Students who had just a 6-week vacation lost very little knowledge as measured by a benchmark test (a score of 42.88 at the beginning of the vacation dropped to 40.11 after 6 weeks). In contrast, students who had a 12-week vacation dropped from a score of 41.94 to 34.03." id="fig_6.12"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-12">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.12.jpg" alt="Bar graph showing that loss of mathematical knowledge for first-, second-, and third-grade students over the summer period is greater when the vacation period is longer. Students who had just a 6-week vacation lost very little knowledge as measured by a benchmark test (a score of 42.88 at the beginning of the vacation dropped to 40.11 after 6 weeks). In contrast, students who had a 12-week vacation dropped from a score of 41.94 to 34.03." title="Bar graph showing that loss of mathematical knowledge for first-, second-, and third-grade students over the summer period is greater when the vacation period is longer. Students who had just a 6-week vacation lost very little knowledge as measured by a benchmark test (a score of 42.88 at the beginning of the vacation dropped to 40.11 after 6 weeks). In contrast, students who had a 12-week vacation dropped from a score of 41.94 to 34.03." id="fig_6.12"/>
 	  </div>
   </section>


       
	   <div class="single-column">
          <p class="txt">Unlike formative assessments, benchmark assessments are not an intrinsic part of ongoing instruction: They are not designed specifically to provide teachers and learners with information that is immediately useful for modifying and improving teaching and learning. </p>
          <p class="key-point">Instead, they are periodic summative assessments. </p>
          <p class="txt">In many jurisdictions, they are uniform across grades and schools. Simply put, their main purpose is to show progress by evaluating or checking achievement in comparison with a standard (a benchmark).</p>
          <p class="txt">Benchmark testing can also be part of preinstruction, <em>placement</em> assessment. For example, Burns and associates (2017) report a study in which benchmark assessments given to third-grade ELL students prior to the school year indicated that oral fluency for some fell below the benchmark criterion. These learners were selected for reading interventions that occurred throughout the school year. Benchmark assessments at the end of the school year indicated that students selected for intervention had made the most progress during the year.</p>
          <p class="txt">A large number of benchmark assessments are available, many of them commercially prepared; others are developed locally by teachers or by personnel at the district or state level. One example is DIBELS, discussed in Chapter 5. DIBELS is a collection of benchmark measures that looks at sequential growth and development of early literacy skills. Its main purpose is to identify children who need intervention and to assess the adequacy of intervention strategies. To accomplish this, it looks at benchmarks in developing reading skills, such as the child&#39;s awareness of the sounds of letters (phonological awareness) and ability to recognize syllables. One of the benchmark DIBELS tests, for example, asks students to read nonsense words. Doing so correctly reflects knowledge of letter&ndash;sound correspondences (rather than simple recognition of a word pattern learned by rote).</p>
       </div>

    </div>

   	<a id="p265"></a>
   <h2 class="h2">Characteristics of Useful Benchmark Assessments</h2>
   <div class="single-column">
          <p class="txt">As is the case for all educational assessment instruments, the most useful benchmark assessments are characterized by the qualities of good measuring instruments: test fairness, validity, reliability, and alignment with instruction, curriculum, and instructional objectives. Alignment with state standards is especially important for commercially prepared benchmark assessments, because not all of them reflect the goals of all state educational systems.</p>
          <p class="txt">Accordingly, teachers who want to prepare their own benchmark tests might profit from the guidelines summarized in Table 6.3.</p>
   </div>

   <div class="tbl_scroll_on_mobile">
   <table class="tbl-xl">
          <caption class="tbl_name">
          <span class="tbl_number">Table 6.3</span> <br />
          <span class="tbl_title">Guidelines for teacher-prepared benchmark assessment</span>
          </caption>
          <thead class="tbl_header">
            <tr>
              <th>Step</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> 1.	Align with state standards.</td>
              <td>Build tests that reflect state standards and parallel statewide assessments. </td>
            </tr>
            <tr>
              <td>2.	Map content. </td>
              <td>Ensure alignment by &quot;mapping&quot; curriculum content according to skills and concepts learners need to acquire. </td>
            </tr>
            <tr>
              <td>3.	Focus on big ideas.</td>
              <td>Build around the key ideas that define curriculum. </td>
            </tr>
		    <tr>
              <td>4.	Attend to characteristics of good measuring instruments. </td>
              <td>Ensure that benchmark assessments are fair, valid, and reliable. </td>
            </tr>
            <tr>
              <td>5.	Consider feasibility and utility.</td>
              <td>Consider whether benchmark testing improves student learning and the extent to which test results are meaningful and useful. Is the testing program worth the effort, time, and money expended? </td>
            </tr>
          </tbody>
          <tfoot class="no-border">
            <tr>
              <td colspan="2"><em>Source: Based on &quot;Making benchmark testing work,&quot; by J. L. Herman and E. L. Baker, 2005, </em>Educational Leadership, 63<em> (3), pp. 48&ndash;54.</em></td>
            </tr>
          </tfoot>
     </table>
	 </div>

   <div class="single-column">
          <p class="txt">Although their main purpose is to monitor progress toward final goals, benchmark assessments serve a number of other purposes (Herman, Osmundson, &amp; Dietel, 2010).</p>

           	<ol class="nl">
	           <li class="li_text">They help teachers recognize learners who are in need of help.</li>
	           <li class="li_text">They communicate expectations not only to learners but also to teachers and parents. Implicit in the content of benchmark assessments is information about what is important to learn.</li>
	           <li class="li_text">As a way of monitoring student progress, they also provide teachers and school systems with information about the effectiveness and appropriateness of instructional materials and strategies.</li>
	           <li class="li_text">By providing ongoing evaluation and monitoring of student progress, they yield information that can guide instruction.</li>
	       </ol>

   	<a id="p266"></a>
		  <p class="txt">Interestingly, there also is evidence that benchmark testing can improve student learning (Shrago &amp; Smith, 2006). Hence, it serves formative as well as summative purposes. The identifying characteristics of benchmark assessment are summarized in Figure 6.13.</p>
   </div>


   <figure class="figure-1">
	   <figcaption>
	   <h4 class="figure_name"> <span class="figure_number">Figure 6.13</span><br />
          <span class="figure_title">Characteristics of benchmark assessments</span> </h4>
          <p class="caption">Benchmark assessments are designed to assess the learner&#39;s progress toward course standards. They are intended mainly as periodic summative assessments.</p>
		  <p class="src"></p>
	   </figcaption>

          <a class="trigger-readmore_for_Figure" href="#fig6-13" data-type="tipTrigger">
	        <img src="figures/Figure_6.13.jpg" alt="List of benchmark assessment characteristics, including monitor learner progress toward final goals; commercially prepared by test-preparation firms; may be part of published text-related instructional material for a course; are given usually at least three times a year, but sometimes as often as monthly; focus mainly on core subjects such as reading and mathematics; reflect statewide standards or school district standards; and provide a &quot;benchmark&quot; measure of learner progress relative to state standards." title="List of benchmark assessment characteristics, including monitor learner progress toward final goals; commercially prepared by test-preparation firms; may be part of published text-related instructional material for a course; are given usually at least three times a year, but sometimes as often as monthly; focus mainly on core subjects such as reading and mathematics; reflect statewide standards or school district standards; and provide a &quot;benchmark&quot; measure of learner progress relative to state standards." id="fig_6.13"/>
	     </a>
   </figure>

   <section class="tipBox" id="fig6-13">
      <div class="box-6">
        <img class="trigger-readmore_zoom" src="figures/Figure_6.13.jpg" alt="List of benchmark assessment characteristics, including monitor learner progress toward final goals; commercially prepared by test-preparation firms; may be part of published text-related instructional material for a course; are given usually at least three times a year, but sometimes as often as monthly; focus mainly on core subjects such as reading and mathematics; reflect statewide standards or school district standards; and provide a &quot;benchmark&quot; measure of learner progress relative to state standards." title="List of benchmark assessment characteristics, including monitor learner progress toward final goals; commercially prepared by test-preparation firms; may be part of published text-related instructional material for a course; are given usually at least three times a year, but sometimes as often as monthly; focus mainly on core subjects such as reading and mathematics; reflect statewide standards or school district standards; and provide a &quot;benchmark&quot; measure of learner progress relative to state standards." id="fig_6.13"/>
 	  </div>
   </section>

  </div> 
  <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>



<!--
/////////////////////////////////////////////////////////////
///////////////////////// 6.11 ///////////////////////////////
/////////////////////////////////////////////////////////////
-->



<section class="page" id="sec6.11">
  <div class="section-header">
    <h1 class="h1"><span class="sec_number">6.11</span> <span class="sec_title">A Reminder: The Main Purpose of Educational Assessment</span></h1>
    <h2 class="focus"><span class="focus_lbl">Focus Question</span> <span class="focus_q">What is the main purpose of educational assessment?</span></h2>
  </div>
  <div class="section-lead">     
	   <p class="intro">As stated in Chapter 1, the most important purpose of all the different approaches to educational assessment is to foster learning.</p>
  </div>

<div class="section-body">
    <div class="single-column">
          <p class="txt">True, the specific purpose of summative assessment is to summarize learner progress and achievement and to provide learning-relevant information that can then be communicated to learners (and others). Similarly, the defining purpose of diagnostic assessment is to identify (diagnose) problems and weaknesses, serving primarily as a form of preinstruction, placement assessment. The main purpose of placement assessment is to provide a basis for selection and placement. And the chief purpose of formative assessment is to provide information that is immediately useful to teachers and learners. </p>
          <p class="key-point">But ultimately, the goal of all these assessments is to help learners. </p>
          <p class="txt">It is also important to keep in mind that test items, informal questions, and the variety of tasks that might be used for assessment are not, in and of themselves, summative, formative, diagnostic, or placement. Rather, we label them that way depending on how they are used.</p>
          <p class="txt">In Chapter 7 we will look at a large variety of tasks that can be used for summative, formative, diagnostic, or placement purposes. These tasks fall under the general label of performance assessment.</p>
    </div>

 </div> 
 <script type="text/javascript" src="Scripts/app-min.js"></script>
</section>



<!--
/////////////////////////////////////////////////////////////
///////////////////////// EOC //////////////////////////////
/////////////////////////////////////////////////////////////
-->


<section class="page" id="ch6_summary">

   	<a id="p267"></a>
  <div class="chapter-review-header">
    <h1 class="eoc_h1"><strong>Chapter 6<br />
      </strong> Themes and Questions</h1>
    <div class="seperator">&nbsp;</div>
  </div>
  <div class="chapter-review">
    <h2 class="h2">Themes</h2>
    <div class="single-column">
      <h3 class="h3"> Summative Assessment</h3>
         <p class="txt">Although educational assessments can be distinguished in terms of their main purposes, the overall goal of all forms of educational assessment is to provide learners with the best educational experience possible, maximizing the attainment of learning goals. The main purpose of summative assessment is to provide an indication of achievement after a unit of study, after a term, or at year-end. Given its importance and implications, summative assessment should be carefully planned and aligned with educational standards (<em>backward design approach</em>). In summative assessment learner performance might be compared to that of other learners (norm-referenced), to predetermined criteria (criterion-referenced), or to the individual&#39;s prior or expected performance (self-referenced).</p>

      <h3 class="h3">Norm-Referenced Comparisons</h3>
          <p class="txt">In norm-referenced approaches, the performance of other students sets the <em>norm</em> or <em>standard</em> to which the individual is compared. This interpretation is highly compatible with competitive approaches to education. It permits relative ranking of learners and is therefore useful for comparing learners and for predicting future performance. </p>

      <h3 class="h3">Criterion-Referenced Comparisons</h3>
          <p class="txt">Comparing individual performance to predetermined standards is the basis of criterion-referenced interpretations. Standards in education (an equivalent term is <em>criteria</em>) are often set by states and may be common across states (the CCSS). Adherence to these standards defines <em>standards-based education</em>. Where educational goals and instructional objectives are determined by state standards, it is important that there be alignment between the standards, instructional objectives, assessments, and approaches to teaching. </p>

 
     <h3 class="h3">Self-Referenced Comparisons</h3>
          <p class="txt">Self-referenced interpretations involve comparisons to the individual&#39;s own prior or expected performance. This approach to assessment is useful for gauging learner progress and often has important motivational consequences. It might also be adversely affected by biases and inappropriate teacher, parent, and learner expectations. </p>

	 <h3 class="h3">Criterion-Based Instructional Systems</h3>
          <p class="txt">Instructional systems based on criterion-referenced interpretations are designed to develop competency relative to specific criteria and are known as <em>competency-based</em> systems. Among the better known competency-based systems is Bloom&#39;s mastery learning, which is based on the assumption that all learners can master course content if given sufficient time and support, and Keller&#39;s Personalized System of Instruction (PSI), which breaks textual material into small units with accompanying objectives, study guides, and quizzes. Several online schools also use competency-based systems. These approaches make extensive use of formative assessment as learners progress through content that has been divided into small, sequential steps. Some use technological resources such as an ITS. There is evidence that these approaches can be highly effective. However, they are time consuming and sometimes difficult to organize and implement.</p>

   	<a id="p268"></a>
	 <h3 class="h3">Applications of Summative Assessment</h3>
          <p class="txt">Planning for summative assessment requires a clear view of instructional objectives as well as decisions about approaches to assessment and the use of assessment results and decisions about instructional strategies. <em>Curriculum-based measurement (CBM)</em> is a form of assessment that uses <em>probes</em> that are embedded in the curriculum to gauge learner progress. Benchmark assessments are periodic summative assessments of learner progress, most often administered at regular intervals during a term. They are also sometimes used prior to an instructional sequence for placement purposes or to provide information useful for instruction. They can also be used at the end of a unit or term to provide summative information. The main purpose of all educational assessment is to foster learning.</p>


    </div>
    <h2 class="h2">Applied Questions</h2>
    <div class="single-column">
      <ol class="applied-questions">
        <li class="li_text"><em>What is summative assessment?</em> Explain the identifying distinctions between summative and formative assessment in terms of their main uses.</li>
        <li class="li_text"><em>What are the main differences between norm-referenced and criterion-referenced interpretations of assessment data?</em> Design a graphic that compares norm-referenced, criterion-referenced, and self-referenced comparisons.</li>
        <li class="li_text"><em>How can standards be used for criterion-referenced comparisons?</em> Identify several of your state&#39;s most important standards in your area of interest/expertise and formulate related criteria that might serve as a basis for summative evaluations at a specific grade level.</li>
        <li class="li_text"><em>What are some of the advantages and disadvantages of self-referenced comparisons?</em> In a mock debate with yourself, argue the pros and cons of self-referenced comparisons for first-grade students and for secondary-school learners.</li>
        <li class="li_text"><em>What are some instructional systems based on criterion-referenced comparisons?</em> Using library and online resources, write a brief description and evaluation of competency-based instructional and assessment systems, or research the application of artificial intelligence in instructional systems.</li>
        <li class="li_text"><em>What is curriculum-based and benchmark measurement?</em> Design sample items that might be used as CBM probes in your area of expertise. Explain how these could or could not be used as benchmark assessments</li>

      </ol>
    </div>

 
    <h2 class="h2">Key Terms</h2>
	  <script type="text/javascript"> (function(a){a.fn.answerToggle=function(b){var b=a.extend({revealClass:".reveal"},b),c=a(b.revealClass);this.length!=c.length?console.log(this.length,c.length):(a(b.revealClass).hide(),this.each(function(b){var d=a(c[b]);a(this).click(function(a){a.preventDefault();d.slideToggle("fast")})}))}})(jQuery);
$('document').ready(function(){
$('.answerToggle').answerToggle('.reveal');
}); </script>
    <div class="single-column">
          <p class="tx"><a href="#" class="answerToggle"><strong>benchmark assessment</strong></a>&ensp;</p>
<p class="reveal">Periodic assessments undertaken during instruction and used to monitor learner progress toward learning targets.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>CBM probes</strong></a>&ensp;</p>
<p class="reveal">Standardized sets of test items and quizzes used in curriculum-based measurement; typically available for mathematics, spelling, reading, and writing.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>common core standards</strong></a>&ensp;</p>
<p class="reveal">Statements of basic, minimum requirements that describe the skills and knowledge students are expected to develop in core subjects at each grade level and that are common to more than one school or school system.</p>

   	<a id="p269"></a>
	      <p class="tx"><a href="#" class="answerToggle"><strong>criterion-referenced</strong></a>&ensp;</p>
<p class="reveal">An assessment procedure in which the student is judged relative to a criterion rather than relative to the performance of other students. Compare with <em>norm-referenced</em>.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>curriculum-based measurement (CBM)</strong></a>&ensp;</p>
<p class="reveal">The assessment of skills and knowledge related directly to curriculum content; used as an indicator of learning progress and to assist learning and instruction (formative function) rather than as an indicator of achievement (summative function).</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>norming group</strong></a>&ensp;</p>
<p class="reveal">A group (sample), judged to be representative of a target population, that serves to set the standards for commercially prepared tests designed for that population.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>norm-referenced</strong></a>&ensp;</p>
<p class="reveal">A type of assessment in which the student competes against the performance of other students rather than in relation to a preestablished criterion of acceptable performance. Compare with <em>criterion-referenced</em>. </p>
          <p class="tx"><a href="#" class="answerToggle"><strong>objective tests</strong></a>&ensp;</p>
<p class="reveal">A test consisting of questions for which responses are typically brief, factual, and unambiguous. Multiple-choice, matching, and fill-in-the-blanks tests are typically objective tests.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>overachievement</strong></a>&ensp;</p>
<p class="reveal">The act of achieving at a higher level than expected on the basis of assumed skills, ability, and experience; it is literally impossible to do so. The term carries negative connotations.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>percentile</strong></a>&ensp;</p>
<p class="reveal">The point at or below which a specified proportion of cases in a distribution lie. For example, the 70th percentile is the point (score) at or below which 70% of all scores in the sample fall.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>Personalized System of Instruction (PSI)</strong></a>&ensp;</p>
<p class="reveal">A <em>mastery learning </em>instructional approach in which course material is broken down into small units, study is largely individual, a variety of study material is available, and progress depends on performance on criterion-referenced unit tests.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>portfolio</strong></a>&ensp;</p>
<p class="reveal">A collection of actual samples of students&#39; performances and achievements used for assessment.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>self-referenced approach to assessment</strong></a>&ensp;</p>
<p class="reveal">Assessment that compares the learner&#39;s current performance with performance at some earlier time or with expected performance based on ability, experience, and other personal factors.</p>
          <p class="tx"><a href="#" class="answerToggle"><strong>underachievers</strong></a>&ensp;</p>
<p class="reveal">Those whose achievement and progress is less than what might be expected based on their presumed abilities.</p>

    </div>
  </div>

</section>
<script type="text/javascript" src="Scripts/app-min.js"></script>

</body>
</html>
